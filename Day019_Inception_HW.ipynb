{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    },
    "colab": {
      "name": "Day019_Inception_HW.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/crea0414/1st_CVDL/blob/master/Day019_Inception_HW.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W0QRo24Jk-M8"
      },
      "source": [
        "## 『本次練習內容』\n",
        "#### 學習如何搭建Inception Block"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vZjA732Kk-M-"
      },
      "source": [
        "## 『本次練習目的』\n",
        "  #### 了解Inceotion原理\n",
        "  #### 了解如何導入Inception block到原本架構中"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_AuL1w8GlOmd",
        "outputId": "0a2e91ff-49e9-4365-c30b-71895ee98371",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.__version__"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.3.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZQlwRjkhTAfF"
      },
      "source": [
        "## ConvBN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_1uRyV765gsB"
      },
      "source": [
        "# Conv2d witout \"bias\"\n",
        "# BatchNormalization shoud set scale False (not applied gamma) when next activation is tf.nn.relu\n",
        "\n",
        "class Conv2D_BN(tf.keras.layers.Layer):\n",
        "    def __init__(self, filters, kernel_size, strides=(1, 1), padding='same', activation='relu', name=None, **kwargs):\n",
        "        super(Conv2D_BN, self).__init__(**kwargs)\n",
        "        self.filters = filters\n",
        "        self.kernel_size = kernel_size\n",
        "        self.strides = strides\n",
        "        self.padding = padding\n",
        "        self.activation = activation\n",
        "    \n",
        "    def build(self, input_shape):\n",
        "        self.conv2d = tf.keras.layers.Conv2D(self.filters, self.kernel_size,\n",
        "                                             self.strides, self.padding, use_bias=False)\n",
        "        self.batchnorm = tf.keras.layers.BatchNormalization(axis=-1, scale=False)\n",
        "        self.activate_layer = tf.keras.layers.Activation(self.activation)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x = self.conv2d(inputs)\n",
        "        x = self.batchnorm(x)\n",
        "        x = self.activate_layer(x)\n",
        "        return x\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uhdEmwee95JH",
        "outputId": "e1aec8d1-7e8c-44a8-80fb-a370a422a9b7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#check\n",
        "tf.keras.backend.clear_session()\n",
        "conv2d_bn = Conv2D_BN(64, (3,3))\n",
        "model = tf.keras.Sequential([conv2d_bn])\n",
        "output = model(tf.random.normal((1, 224, 224, 1)))\n",
        "model.summary()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_bn (Conv2D_BN)        (1, 224, 224, 64)         768       \n",
            "=================================================================\n",
            "Total params: 768\n",
            "Trainable params: 640\n",
            "Non-trainable params: 128\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qmj1aDFCIxRm",
        "outputId": "c5f740df-77d2-4d4e-c8aa-231f0a9b35ee",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#with bias and bn applied scale \n",
        "print((3*3*1+1)*64+64*4)\n",
        "#without bias and bn scale off\n",
        "(3*3*1)*64+64*3"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "896\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "768"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vojhDbxP_DZZ",
        "outputId": "fd9965b2-5580-4f5f-ba44-f697872ca8f6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#with bias\n",
        "print(f'parameters_count: conv-{(3*3*1+1)*64} batchnorm-(output_chanels*(gamma+betta+moving_mean+moving_var){64*4}')\n",
        "#without bias\n",
        "print(f'parameters_count: conv-{(3*3*1)*64} batchnorm-(output_chanels*(betta+moving_mean+moving_var){64*3}')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "parameters_count: conv-640 batchnorm-(output_chanels*(gamma+betta+moving_mean+moving_var)256\n",
            "parameters_count: conv-576 batchnorm-(output_chanels*(betta+moving_mean+moving_var)192\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jf0TKgNzALZs"
      },
      "source": [
        "#Inception V2 Block"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q_QdY5hSAPWA"
      },
      "source": [
        "class InceptionV2Block(tf.keras.layers.Layer):\n",
        "    def __init__(self, filters_spec = ((64,), (96, 128), (16, 32), (32,)), **kwargs):\n",
        "        super(InceptionV2Block, self).__init__(**kwargs)\n",
        "        self.branch_0 = filters_spec[0][0]\n",
        "        self.branch_1 = filters_spec[1]\n",
        "        self.branch_2 = filters_spec[2]\n",
        "        self.branch_3 = filters_spec[3][0]\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.conv2d_b0 = Conv2D_BN(self.branch_0, kernel_size=(1, 1))\n",
        "        self.conv2d_b1 = Conv2D_BN(self.branch_1[0], (1, 1))\n",
        "        self.conv2d_b1_1 = Conv2D_BN(self.branch_1[1], (3, 3))\n",
        "        self.conv2d_b2 = Conv2D_BN(self.branch_2[0], (1, 1))\n",
        "        self.conv2d_b2_1 = Conv2D_BN(self.branch_2[1], (3, 3))\n",
        "        self.max_pool = tf.keras.layers.MaxPool2D(pool_size=(3, 3), strides=(1, 1), padding='same')\n",
        "        self.conv2d_b3 = Conv2D_BN(self.branch_3, (1, 1))\n",
        "    \n",
        "    def call(self, inputs):\n",
        "        b0 = self.conv2d_b0(inputs)\n",
        "        b1 = self.conv2d_b1(inputs)\n",
        "        b1_1 = self.conv2d_b1_1(b1)\n",
        "        b2 = self.conv2d_b2(inputs)\n",
        "        b2_1 = self.conv2d_b2_1(b2)\n",
        "        b3 = self.max_pool(inputs)\n",
        "        b3_1 = self.conv2d_b3(b3)\n",
        "        \n",
        "        return tf.concat([b0, b1_1, b2_1, b3_1], axis=-1)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EN9k4nYPEWi-",
        "outputId": "ae12029c-5fcb-40f9-fab2-fbc3e3f5df4a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#check \n",
        "tf.keras.backend.clear_session()\n",
        "\n",
        "inception_block = InceptionV2Block()\n",
        "model = tf.keras.Sequential([inception_block])\n",
        "output = model(tf.random.normal((1, 224, 224, 1)))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "inception_v2block (Inception (1, 224, 224, 256)        116512    \n",
            "=================================================================\n",
            "Total params: 116,512\n",
            "Trainable params: 115,776\n",
            "Non-trainable params: 736\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pTqcxt_rPw30",
        "outputId": "5de52009-d465-49c8-b908-da0c60245121",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#with bias and bn applied scale \n",
        "in_ch = 1\n",
        "(1*1*in_ch)*64 + 64*3 + \\\n",
        "(1*1*in_ch)*96 + 96*3 + (3*3*96)*128 + 128*3 + \\\n",
        "(1*1*in_ch)*16 + 16*3 + (5*5*16)*32 + 32*3 + \\\n",
        "(1*1*in_ch)*32 + 32*3 , (64*2 + 96*2 + 128*2 + 16*2 + 32*2 + 32*2 )"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(124704, 736)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oFvmaZD_FfFc",
        "outputId": "17cf1642-4245-4662-f6de-f419bb27b4c9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#without bias and bn scale off\n",
        "in_ch = 1\n",
        "(1*1*in_ch+1)*64 + 64*4 + \\\n",
        "(1*1*in_ch+1)*96 + 96*4 + (3*3*96+1)*128 + 128*4 + \\\n",
        "(1*1*in_ch+1)*16 + 16*4 + (5*5*16+1)*32 + 32*4 + \\\n",
        "(1*1*in_ch+1)*32 + 32*4 , (64*2 + 96*2 + 128*2 + 16*2 + 32*2 + 32*2 )"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(125440, 736)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ANwrmQshLEbs"
      },
      "source": [
        "# Inception V3 Block"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bqnvDi-DLDxi"
      },
      "source": [
        "class InceptionV3Block(tf.keras.layers.Layer):\n",
        "    def __init__(self, filters_spec = ((64,), (96, 128), (16, 32), (32,)), **kwargs):\n",
        "        super(InceptionV3Block, self).__init__(**kwargs)\n",
        "        self.branch_0 = filters_spec[0][0]\n",
        "        self.branch_1 = filters_spec[1]\n",
        "        self.branch_2 = filters_spec[2]\n",
        "        self.branch_3 = filters_spec[3][0]\n",
        "    \n",
        "    def build(self, input_shape):\n",
        "        self.conv2d_0 = Conv2D_BN(self.branch_0, (1, 1))\n",
        "        self.conv2d_1 = Conv2D_BN(self.branch_1[0], (1, 1))\n",
        "        self.conv2d_1_1 = Conv2D_BN(self.branch_1[1], (1, 3))\n",
        "        self.conv2d_1_2 = Conv2D_BN(self.branch_1[1], (3, 1))\n",
        "        self.conv2d_2 = Conv2D_BN(self.branch_2[0], (1, 1))\n",
        "        self.conv2d_2_1 = Conv2D_BN(self.branch_2[1], (1, 3))\n",
        "        self.conv2d_2_2 = Conv2D_BN(self.branch_2[1], (3, 1))\n",
        "        self.max_pool = tf.keras.layers.MaxPool2D(pool_size=(3, 3), strides=(1, 1), padding='same')\n",
        "        self.conv2d_3 = Conv2D_BN(self.branch_3, (1, 1))\n",
        "        \n",
        "    def call(self, inputs):\n",
        "        b0 = self.conv2d_0(inputs)\n",
        "        b1 = self.conv2d_1(inputs)\n",
        "        b1_1 = self.conv2d_1_1(b1)\n",
        "        b1_2 = self.conv2d_1_2(b1_1)\n",
        "        b2 = self.conv2d_2(inputs)\n",
        "        b2_1 = self.conv2d_2_1(b2)\n",
        "        b2_2 = self.conv2d_2_2(b2_1)\n",
        "        b3 = self.max_pool(inputs)\n",
        "        b3_1 = self.conv2d_3(b3)\n",
        "        return tf.concat([b0, b1_2, b2_2, b3_1], axis=-1)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8rGKwtblN9VN",
        "outputId": "935ee2c8-5c05-4690-ce40-bf7f78636598",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#check \n",
        "tf.keras.backend.clear_session()\n",
        "\n",
        "inception_block = InceptionV3Block()\n",
        "model = tf.keras.Sequential([inception_block])\n",
        "output = model(tf.random.normal((1, 224, 224, 1)))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "inception_v3block (Inception (1, 224, 224, 256)        92416     \n",
            "=================================================================\n",
            "Total params: 92,416\n",
            "Trainable params: 91,360\n",
            "Non-trainable params: 1,056\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wTpvfST0idSj",
        "outputId": "9cadda56-7f88-45cc-f4a2-75f6c607b91c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#count total params\n",
        "in_ch = 1\n",
        "(1*1*in_ch)*64 + 3*64 + \\\n",
        "(1*1*in_ch)*96 + 3*96 + (1*3*96)*128 + 3*128 + (3*1*128)*128 + 3*128 + \\\n",
        "(1*1*in_ch)*16 + 3*16 + (1*3*16)*32 + 3*32 + (3*1*32)*32 + 3*32 + \\\n",
        "(1*1*in_ch)*32 + 3*32 "
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "92416"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zZlMFo-vlMbl"
      },
      "source": [
        "# VGG16"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ono4HJxLle2z",
        "outputId": "7e99d699-ed44-4757-d572-2d44e2a599ab",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "vgg16 = tf.keras.applications.VGG16()\n",
        "vgg16.summary()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "fc1 (Dense)                  (None, 4096)              102764544 \n",
            "_________________________________________________________________\n",
            "fc2 (Dense)                  (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "predictions (Dense)          (None, 1000)              4097000   \n",
            "=================================================================\n",
            "Total params: 138,357,544\n",
            "Trainable params: 138,357,544\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LqrjB71ul5OA"
      },
      "source": [
        "class VggBlockConvBN2(tf.keras.layers.Layer):\n",
        "    def __init__(self, filters, kernel_size=(3, 3), **kwargs):\n",
        "        super(VggBlockConvBN2, self).__init__(**kwargs)\n",
        "        self.filters = filters\n",
        "        self.kernel_size = kernel_size\n",
        "    def build(self, input_shape):\n",
        "        self.conv1 = Conv2D_BN(self.filters, self.kernel_size, padding='same')\n",
        "        self.conv2 = Conv2D_BN(self.filters, self.kernel_size, padding='same')\n",
        "        self.max_pool = tf.keras.layers.MaxPool2D(pool_size=(2, 2), strides=(2, 2), padding='valid')\n",
        "    def call(self, inputs):\n",
        "        x = self.conv1(inputs)\n",
        "        x = self.conv2(x)\n",
        "        return self.max_pool(x)\n",
        "\n",
        "class VggBlockConvBN3(tf.keras.layers.Layer):\n",
        "    def __init__(self, filters, kernel_size=(3, 3), **kwargs):\n",
        "        super(VggBlockConvBN3, self).__init__(**kwargs)\n",
        "        self.filters = filters\n",
        "        self.kernel_size = kernel_size\n",
        "    def build(self, input_shape):\n",
        "        self.conv1 = Conv2D_BN(self.filters, self.kernel_size, padding='same')\n",
        "        self.conv2 = Conv2D_BN(self.filters, self.kernel_size, padding='same')\n",
        "        self.conv3 = Conv2D_BN(self.filters, self.kernel_size, padding='same')\n",
        "        self.max_pool = tf.keras.layers.MaxPool2D(pool_size=(2, 2), strides=(2, 2), padding='valid')\n",
        "    def call(self, inputs):\n",
        "        x = self.conv1(inputs)\n",
        "        x = self.conv2(x)\n",
        "        x = self.conv3(x)\n",
        "        return self.max_pool(x)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SyoM6vVDnoSR",
        "outputId": "b93ccd72-9f1a-406f-a95a-8633f218e10b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "tf.keras.backend.clear_session()\n",
        "vgg_block2 = VggBlockConvBN2(64)\n",
        "model = tf.keras.Sequential([vgg_block2])\n",
        "_ = model(tf.random.normal((1, 224, 224, 1)))\n",
        "\n",
        "vgg_block3 = VggBlockConvBN3(64)\n",
        "model2 = tf.keras.Sequential([vgg_block3])\n",
        "_ = model2(tf.random.normal((1, 224, 224, 1)))\n",
        "\n",
        "model.summary(), model2.summary()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "vgg_block_conv_b_n2 (VggBloc (1, 112, 112, 64)         37824     \n",
            "=================================================================\n",
            "Total params: 37,824\n",
            "Trainable params: 37,568\n",
            "Non-trainable params: 256\n",
            "_________________________________________________________________\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "vgg_block_conv_b_n3 (VggBloc (1, 112, 112, 64)         74880     \n",
            "=================================================================\n",
            "Total params: 74,880\n",
            "Trainable params: 74,496\n",
            "Non-trainable params: 384\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(None, None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SmUXP_ywoFuU",
        "outputId": "3bebc517-2c50-489c-a9b0-1ac9cd472f50",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "params = (3*3*1)*64 + 64*3 + (3*3*64)*64 + 64*3\n",
        "params2 = (3*3*1)*64 + 64*3 + (3*3*64)*64 + 64*3 + (3*3*64)*64 + 64*3 \n",
        "params, params2"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(37824, 74880)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7RzdMkhPpHwO"
      },
      "source": [
        "class MyVGG16BN(tf.keras.Model):\n",
        "    def __init__(self, include_top=True, pooling='max', classes=1000, **kwargs):\n",
        "        super(MyVGG16BN, self).__init__(**kwargs)\n",
        "        self.block1 = VggBlockConvBN2(64)\n",
        "        self.block2 = VggBlockConvBN2(128)\n",
        "        self.block3 = VggBlockConvBN3(256)\n",
        "        self.block4 = VggBlockConvBN3(512)\n",
        "        self.block5 = VggBlockConvBN3(512)\n",
        "        self.classes = classes\n",
        "        self.include_top = include_top\n",
        "        self.pooling = pooling\n",
        "        \n",
        "        if self.include_top:\n",
        "            self.flatten = tf.keras.layers.Flatten()\n",
        "            self.dense1 = tf.keras.layers.Dense(4096)\n",
        "            self.bn1 = tf.keras.layers.BatchNormalization()\n",
        "            self.dense2 = tf.keras.layers.Dense(4096)\n",
        "            self.bn2 = tf.keras.layers.BatchNormalization()\n",
        "            self.dense3 = tf.keras.layers.Dense(self.classes)\n",
        "        else:\n",
        "            if self.pooling == 'max':\n",
        "                self.pooling_layer = tf.keras.layers.GlobalMaxPooling2D()\n",
        "            else:\n",
        "                self.pooling_layer = tf.keras.layers.GlobalAveragePooling2D()\n",
        "        \n",
        "    def call(self, inputs):\n",
        "        x = self.block1(inputs)\n",
        "        x = self.block2(x)\n",
        "        x = self.block3(x)\n",
        "        x = self.block4(x)\n",
        "        x = self.block5(x)\n",
        "\n",
        "        if self.include_top:\n",
        "            x = self.flatten(x)\n",
        "            x = self.dense1(x)\n",
        "            x = self.bn1(x)\n",
        "            x = tf.nn.relu(x)\n",
        "            x = self.dense2(x)\n",
        "            x = self.bn2(x)\n",
        "            x = tf.nn.relu(x)\n",
        "            x = self.dense3(x)\n",
        "            return tf.nn.softmax(x)\n",
        "        else:\n",
        "            x = self.pooling_layer(x)\n",
        "            return x"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pwc5HYYSsF7-",
        "outputId": "6e582aec-06fd-439d-9195-126559a2319f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "tf.keras.backend.clear_session()\n",
        "my_vgg16 = MyVGG16BN(include_top=True)\n",
        "output = my_vgg16(tf.random.normal((1, 224, 224, 3)))\n",
        "my_vgg16.summary()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"my_vg_g16bn\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "vgg_block_conv_b_n2 (VggBloc multiple                  38976     \n",
            "_________________________________________________________________\n",
            "vgg_block_conv_b_n2_1 (VggBl multiple                  221952    \n",
            "_________________________________________________________________\n",
            "vgg_block_conv_b_n3 (VggBloc multiple                  1476864   \n",
            "_________________________________________________________________\n",
            "vgg_block_conv_b_n3_1 (VggBl multiple                  5902848   \n",
            "_________________________________________________________________\n",
            "vgg_block_conv_b_n3_2 (VggBl multiple                  7082496   \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            multiple                  0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                multiple                  102764544 \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo multiple                  16384     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              multiple                  16781312  \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch multiple                  16384     \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              multiple                  4097000   \n",
            "=================================================================\n",
            "Total params: 138,398,760\n",
            "Trainable params: 138,373,928\n",
            "Non-trainable params: 24,832\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0BvF4YLgs2xf",
        "outputId": "fe2dc56d-3f5f-4f7c-d11a-5aca74d2854e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#batch params count\n",
        "\n",
        "batch_cnt = 64*4*2 + 128*4*2 + 256*4*3 + 512*4*3*2 + 16384 *2\n",
        "batch_cnt, 138407208 - batch_cnt + (64*2 + 128*2 + 256*2 + 512*2)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(49664, 138359464)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "72Uy0zxE1lI7"
      },
      "source": [
        "# Custom Vgg16\n",
        "- conv_layer in block3 >> inception_v2 block\n",
        "- conv_layer in block5 >> inception_v3 block"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i0ojcf_PYlL4"
      },
      "source": [
        "filter_spec = ((64, ), (96, 128), (16, 32), (32,))\n",
        "filter_spec1 = ((128, ), (192, 256), (32, 64), (64,))"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_nLVHI0ya-pL"
      },
      "source": [
        "filter_spec_a = ((64, ), (96, 128), (16, 32), (32,))\n",
        "filter_spec_b = ((64, ), (96,), (16,), (32,))\n",
        "filter_spec_c = ((128, ), (192, 256), (32, 64), (64,))"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QUjMisn65-3l"
      },
      "source": [
        "class VggInceptBlock2(tf.keras.layers.Layer):\n",
        "    def __init__(self, **kwargs):\n",
        "        super(VggInceptBlock2, self).__init__(**kwargs)\n",
        "    def build(self, input_shape):\n",
        "        self.inceptv2 = InceptionV2Block(filter_spec_a)\n",
        "        self.inceptv2_1 = InceptionV2Block(filter_spec_a)\n",
        "        self.inceptv2_2 = InceptionV2Block(filter_spec_a)\n",
        "        self.max_pool = tf.keras.layers.MaxPool2D(pool_size=(2, 2), strides=(2, 2), padding='valid')\n",
        "    def call(self, inputs):\n",
        "        x = self.inceptv2(inputs)\n",
        "        x = self.inceptv2_1(x)\n",
        "        x = self.inceptv2_2(x)\n",
        "        x = self.max_pool(x)\n",
        "        return x\n",
        "\n",
        "class VggInceptBlock3(tf.keras.layers.Layer):\n",
        "    def __init__(self, **kwargs):\n",
        "        super(VggInceptBlock3, self).__init__(**kwargs)\n",
        "    def build(self, input_shape):\n",
        "        self.inceptv3 = InceptionV3Block(filter_spec_c)\n",
        "        self.inceptv3_1 = InceptionV3Block(filter_spec_c)\n",
        "        self.inceptv3_2 = InceptionV3Block(filter_spec_c)\n",
        "        self.max_pool = tf.keras.layers.MaxPool2D(pool_size=(2, 2),  strides=(2, 2), padding='valid')\n",
        "    def call(self, inputs):\n",
        "        x = self.inceptv3(inputs)\n",
        "        x = self.inceptv3_1(x)\n",
        "        x = self.inceptv3_2(x)\n",
        "        x = self.max_pool(x)\n",
        "        return x"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AzgNDPk11klm"
      },
      "source": [
        "class InceptVgg16(tf.keras.Model):\n",
        "    def __init__(self, include_top= True, pooling='max', classes=1000, **kwargs):\n",
        "        super(InceptVgg16, self).__init__(**kwargs)\n",
        "        self.block1 = VggBlockConvBN2(64)\n",
        "        self.block2 = VggBlockConvBN2(128)\n",
        "        self.block3 = VggInceptBlock2()\n",
        "        self.block4 = VggBlockConvBN3(512)\n",
        "        self.block5 = VggInceptBlock3()\n",
        "\n",
        "        self.include_top = include_top\n",
        "        self.pooling = pooling\n",
        "        self.classes = classes\n",
        "\n",
        "        if self.include_top:\n",
        "            self.flatten = tf.keras.layers.Flatten()\n",
        "            self.dense1 = tf.keras.layers.Dense(4096)\n",
        "            self.bn1 = tf.keras.layers.BatchNormalization()\n",
        "            self.dense2 = tf.keras.layers.Dense(4096)\n",
        "            self.bn2 = tf.keras.layers.BatchNormalization()\n",
        "            self.dense3 = tf.keras.layers.Dense(self.classes, activation='softmax')\n",
        "        else:\n",
        "            if self.pooling:\n",
        "                self.pooling_layer = tf.keras.layers.GlobalMaxPool2D()\n",
        "            else:\n",
        "                self.pooling_layer = tf.keras.layers.GlobalAveragePooling2D()\n",
        "    \n",
        "    def call(self, inputs):\n",
        "        x = self.block1(inputs)\n",
        "        x = self.block2(x)\n",
        "        x = self.block3(x)\n",
        "        x = self.block4(x)\n",
        "        x = self.block5(x)\n",
        "\n",
        "        if self.include_top:\n",
        "            x = self.flatten(x)\n",
        "            x = self.dense1(x)\n",
        "            x = self.bn1(x)\n",
        "            x = self.dense2(x)\n",
        "            x = self.bn2(x)\n",
        "            x = self.dense3(x)\n",
        "            return x\n",
        "        else:\n",
        "            return self.pooling_layer(x)\n",
        "\n"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "esTcztnu5DYn",
        "outputId": "6ca54683-1b3b-4983-96d1-46582590828a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "tf.keras.backend.clear_session()\n",
        "my_incepVgg = InceptVgg16(include_top=False)\n",
        "output = my_incepVgg(tf.random.normal((1, 224, 224, 1)))\n",
        "my_incepVgg.summary()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"incept_vgg16\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "vgg_block_conv_b_n2 (VggBloc multiple                  37824     \n",
            "_________________________________________________________________\n",
            "vgg_block_conv_b_n2_1 (VggBl multiple                  221952    \n",
            "_________________________________________________________________\n",
            "vgg_incept_block2 (VggIncept multiple                  482032    \n",
            "_________________________________________________________________\n",
            "vgg_block_conv_b_n3 (VggBloc multiple                  5902848   \n",
            "_________________________________________________________________\n",
            "vgg_incept_block3 (VggIncept multiple                  1735968   \n",
            "_________________________________________________________________\n",
            "global_max_pooling2d (Global multiple                  0         \n",
            "=================================================================\n",
            "Total params: 8,380,624\n",
            "Trainable params: 8,368,240\n",
            "Non-trainable params: 12,384\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lzohAa2ikbVX"
      },
      "source": [
        "# Lecture Template\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "po65HMp_GEq5"
      },
      "source": [
        "import tensorflow.keras.backend as K"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mv-SFyWok-NM"
      },
      "source": [
        "## 導入InceptionV2-有BatchNormalization的Convolution\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oPxqW6UclC4L"
      },
      "source": [
        "def Conv2d_bn(x,filters,kernel_size,padding='same',strides=(1, 1),normalizer=True,activation='relu',name=None):\n",
        "    if name is not None:\n",
        "        conv_name = name + '_conv'\n",
        "        bn_name = name + '_bn'\n",
        "        act_name = name + '_act'\n",
        "    else:\n",
        "        conv_name = None\n",
        "        bn_name = None\n",
        "        act_name = None\n",
        "    if K.image_data_format() == 'channels_first':\n",
        "        bn_axis = 1\n",
        "    else:\n",
        "        bn_axis = 3\n",
        "    x = tf.keras.layers.Conv2D(\n",
        "            filters, kernel_size,\n",
        "            strides=strides, padding=padding,\n",
        "            use_bias=False, name=conv_name)(x)\n",
        "    if normalizer:\n",
        "        x = tf.keras.layers.BatchNormalization(axis=bn_axis, scale=False,  name=bn_name)(x)\n",
        "    if activation:\n",
        "        x = tf.keras.layers.Activation(activation, name=act_name)(x)\n",
        "    return x"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U2NNHMoiSH4d",
        "outputId": "7ba1cf0b-56c0-4725-ef19-ba6dc69a3fd6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "tf.keras.backend.clear_session()\n",
        "img_input = tf.keras.layers.Input(shape=(224,224,1))\n",
        "x = Conv2d_bn(img_input, 64, (3, 3))\n",
        "model = tf.keras.Model(img_input, x)\n",
        "model.summary()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 224, 224, 1)]     0         \n",
            "_________________________________________________________________\n",
            "conv2d (Conv2D)              (None, 224, 224, 64)      576       \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 224, 224, 64)      192       \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 224, 224, 64)      0         \n",
            "=================================================================\n",
            "Total params: 768\n",
            "Trainable params: 640\n",
            "Non-trainable params: 128\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5k4eqjY6k-NU"
      },
      "source": [
        "## 參考上圖搭建 \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "36yCLtoIk-NV"
      },
      "source": [
        "def InceptionV1_block(x, specs,channel_axis, name):\n",
        "    (br0, br1, br2, br3) = specs   # ((64,), (96,128), (16,32), (32,))\n",
        "    branch_0 = Conv2d_bn(x, br0[0], (1, 1), name=name+\"_Branch_0\")\n",
        "\n",
        "    branch_1 = Conv2d_bn(x, br1[0], (1, 1), name=name+\"_Branch_1\")\n",
        "    branch_1 = Conv2d_bn(branch_1, br1[1], (3, 3), name=name+\"_Branch_1_1\")\n",
        "\n",
        "    '''Branch_2'''\n",
        "    branch_2 = Conv2d_bn(x, br2[0], (1, 1), name=name+\"_Branch_2\")\n",
        "    branch_2 = Conv2d_bn(branch_2, br2[1], (3, 3), name=name+\"_Branch_2_1\")\n",
        "\n",
        "    '''Branch_3'''\n",
        "    branch_3 = tf.keras.layers.MaxPool2D(pool_size=(3, 3,), strides=(1, 1), padding='same')(x)\n",
        "    branch_3 = Conv2d_bn(branch_3, br3[0], (1, 1), name=name+\"_Branch_3\")\n",
        "    x = tf.keras.layers.concatenate(\n",
        "        [branch_0, branch_1, branch_2, branch_3],\n",
        "        axis=channel_axis,\n",
        "        name=name+\"_Concatenated\")\n",
        "    return x"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VXPmmKgSk-Nb"
      },
      "source": [
        "## 測試"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vIuwC1hKHkJV",
        "outputId": "d7b14258-3396-419b-edd6-a74551a09a00",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "tf.keras.backend.clear_session()\n",
        "img_input = tf.keras.layers.Input(shape=(224,224,1))\n",
        "x=InceptionV1_block(img_input, ((64,), (96,128), (16,32), (32,)), 3, 'Block_1')\n",
        "model = tf.keras.Model(img_input, x)\n",
        "model.summary()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 224, 224, 1) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "Block_1_Branch_1_conv (Conv2D)  (None, 224, 224, 96) 96          input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "Block_1_Branch_2_conv (Conv2D)  (None, 224, 224, 16) 16          input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "Block_1_Branch_1_bn (BatchNorma (None, 224, 224, 96) 288         Block_1_Branch_1_conv[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Block_1_Branch_2_bn (BatchNorma (None, 224, 224, 16) 48          Block_1_Branch_2_conv[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Block_1_Branch_1_act (Activatio (None, 224, 224, 96) 0           Block_1_Branch_1_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "Block_1_Branch_2_act (Activatio (None, 224, 224, 16) 0           Block_1_Branch_2_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 224, 224, 1)  0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "Block_1_Branch_0_conv (Conv2D)  (None, 224, 224, 64) 64          input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "Block_1_Branch_1_1_conv (Conv2D (None, 224, 224, 128 110592      Block_1_Branch_1_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "Block_1_Branch_2_1_conv (Conv2D (None, 224, 224, 32) 4608        Block_1_Branch_2_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "Block_1_Branch_3_conv (Conv2D)  (None, 224, 224, 32) 32          max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "Block_1_Branch_0_bn (BatchNorma (None, 224, 224, 64) 192         Block_1_Branch_0_conv[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Block_1_Branch_1_1_bn (BatchNor (None, 224, 224, 128 384         Block_1_Branch_1_1_conv[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "Block_1_Branch_2_1_bn (BatchNor (None, 224, 224, 32) 96          Block_1_Branch_2_1_conv[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "Block_1_Branch_3_bn (BatchNorma (None, 224, 224, 32) 96          Block_1_Branch_3_conv[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Block_1_Branch_0_act (Activatio (None, 224, 224, 64) 0           Block_1_Branch_0_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "Block_1_Branch_1_1_act (Activat (None, 224, 224, 128 0           Block_1_Branch_1_1_bn[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Block_1_Branch_2_1_act (Activat (None, 224, 224, 32) 0           Block_1_Branch_2_1_bn[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Block_1_Branch_3_act (Activatio (None, 224, 224, 32) 0           Block_1_Branch_3_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "Block_1_Concatenated (Concatena (None, 224, 224, 256 0           Block_1_Branch_0_act[0][0]       \n",
            "                                                                 Block_1_Branch_1_1_act[0][0]     \n",
            "                                                                 Block_1_Branch_2_1_act[0][0]     \n",
            "                                                                 Block_1_Branch_3_act[0][0]       \n",
            "==================================================================================================\n",
            "Total params: 116,512\n",
            "Trainable params: 115,776\n",
            "Non-trainable params: 736\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LJq0xRZYQfC0",
        "outputId": "1d0da3f3-a6ae-4f4d-9329-9715ec802cb9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "in_ch = 1\n",
        "(1*1*in_ch)*64 + 64*3 + \\\n",
        "(1*1*in_ch)*96 + 96*3 + (3*3*96)*128 + 128*3 + \\\n",
        "(1*1*in_ch)*16 + 16*3 + (5*5*16)*32 + 32*3 + \\\n",
        "(1*1*in_ch)*32 + 32*3 , (64*2 + 96*2 + 128*2 + 16*2 + 32*2 + 32*2 )"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(124704, 736)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xbFJ9Zbqk-Ni"
      },
      "source": [
        "## 將 InceptionV1_block中n*n卷積改為1 x n+n x 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V8MUngMkk-Nj"
      },
      "source": [
        "def InceptionV3_block(x, specs, channel_axis, name):\n",
        "    (br0, br1, br2, br3) = specs   # ((64,), (96,128), (16,32), (32,))\n",
        "    branch_0 = Conv2d_bn(x, br0[0], (1, 1), name=name+\"_Branch_0\")\n",
        "\n",
        "    branch_1 = Conv2d_bn(x, br1[0], (1, 1), name=name+\"_Branch_1\")\n",
        "    branch_1 = Conv2d_bn(branch_1, br1[1], (1, 3), name=name+\"_Branch_1_1\")\n",
        "    branch_1 = Conv2d_bn(branch_1, br1[1], (3, 1), name=name+\"_Branch_1_2\")\n",
        "\n",
        "    '''Branch_2'''\n",
        "    branch_2 = Conv2d_bn(x, br2[0], (1, 1), name=name+\"_Branch_2\")\n",
        "    branch_2 = Conv2d_bn(branch_2, br2[1], (1, 3), name=name+\"_Branch_2_1\")\n",
        "    branch_2 = Conv2d_bn(branch_2, br2[1], (3, 1), name=name+\"_Branch_2_2\")\n",
        "    '''Branch_3'''\n",
        "    branch_3 = tf.keras.layers.MaxPool2D(pool_size=(3, 3), strides=(1, 1), padding='same')(x)\n",
        "    branch_3 = Conv2d_bn(branch_3, br3[0], (1, 1), name=name+\"_Branch_3\")\n",
        "\n",
        "    x = tf.keras.layers.concatenate(\n",
        "        [branch_0, branch_1, branch_2, branch_3],\n",
        "        axis=channel_axis,\n",
        "        name=name+\"_Concatenated\")\n",
        "    return x"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z-UhY5Z9k-Np"
      },
      "source": [
        "## 測試"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mnVW4xuik-Nr",
        "outputId": "25c4650e-3ace-4dd5-ab36-54d2b65fbfd6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "tf.keras.backend.clear_session()\n",
        "img_input = tf.keras.layers.Input(shape=(224,224,1))\n",
        "x=InceptionV3_block(img_input, ((64,), (96,128), (16,32), (32,)), 3, 'Block_1')\n",
        "print(x)\n",
        "\n",
        "model = tf.keras.Model(img_input, x)\n",
        "model.summary()"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensor(\"Block_1_Concatenated/concat:0\", shape=(None, 224, 224, 256), dtype=float32)\n",
            "Model: \"functional_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 224, 224, 1) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "Block_1_Branch_1_conv (Conv2D)  (None, 224, 224, 96) 96          input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "Block_1_Branch_2_conv (Conv2D)  (None, 224, 224, 16) 16          input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "Block_1_Branch_1_bn (BatchNorma (None, 224, 224, 96) 288         Block_1_Branch_1_conv[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Block_1_Branch_2_bn (BatchNorma (None, 224, 224, 16) 48          Block_1_Branch_2_conv[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Block_1_Branch_1_act (Activatio (None, 224, 224, 96) 0           Block_1_Branch_1_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "Block_1_Branch_2_act (Activatio (None, 224, 224, 16) 0           Block_1_Branch_2_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "Block_1_Branch_1_1_conv (Conv2D (None, 224, 224, 128 36864       Block_1_Branch_1_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "Block_1_Branch_2_1_conv (Conv2D (None, 224, 224, 32) 1536        Block_1_Branch_2_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "Block_1_Branch_1_1_bn (BatchNor (None, 224, 224, 128 384         Block_1_Branch_1_1_conv[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "Block_1_Branch_2_1_bn (BatchNor (None, 224, 224, 32) 96          Block_1_Branch_2_1_conv[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "Block_1_Branch_1_1_act (Activat (None, 224, 224, 128 0           Block_1_Branch_1_1_bn[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Block_1_Branch_2_1_act (Activat (None, 224, 224, 32) 0           Block_1_Branch_2_1_bn[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 224, 224, 1)  0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "Block_1_Branch_0_conv (Conv2D)  (None, 224, 224, 64) 64          input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "Block_1_Branch_1_2_conv (Conv2D (None, 224, 224, 128 49152       Block_1_Branch_1_1_act[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "Block_1_Branch_2_2_conv (Conv2D (None, 224, 224, 32) 3072        Block_1_Branch_2_1_act[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "Block_1_Branch_3_conv (Conv2D)  (None, 224, 224, 32) 32          max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "Block_1_Branch_0_bn (BatchNorma (None, 224, 224, 64) 192         Block_1_Branch_0_conv[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Block_1_Branch_1_2_bn (BatchNor (None, 224, 224, 128 384         Block_1_Branch_1_2_conv[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "Block_1_Branch_2_2_bn (BatchNor (None, 224, 224, 32) 96          Block_1_Branch_2_2_conv[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "Block_1_Branch_3_bn (BatchNorma (None, 224, 224, 32) 96          Block_1_Branch_3_conv[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Block_1_Branch_0_act (Activatio (None, 224, 224, 64) 0           Block_1_Branch_0_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "Block_1_Branch_1_2_act (Activat (None, 224, 224, 128 0           Block_1_Branch_1_2_bn[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Block_1_Branch_2_2_act (Activat (None, 224, 224, 32) 0           Block_1_Branch_2_2_bn[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Block_1_Branch_3_act (Activatio (None, 224, 224, 32) 0           Block_1_Branch_3_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "Block_1_Concatenated (Concatena (None, 224, 224, 256 0           Block_1_Branch_0_act[0][0]       \n",
            "                                                                 Block_1_Branch_1_2_act[0][0]     \n",
            "                                                                 Block_1_Branch_2_2_act[0][0]     \n",
            "                                                                 Block_1_Branch_3_act[0][0]       \n",
            "==================================================================================================\n",
            "Total params: 92,416\n",
            "Trainable params: 91,360\n",
            "Non-trainable params: 1,056\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2vC6i9suk-Ny"
      },
      "source": [
        "## 額外練習"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SpQARlGak-Nz"
      },
      "source": [
        "## 將VGG16 Block_3中的Convolution全部改為InceptionV1_block\n",
        "## Block_5中的Convolution全部改為InceptionV3_block\n",
        "## 並將所有Convolution改為Conv2d_bn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pLCzoSVxk-N0"
      },
      "source": [
        "#### 原vgg16架構"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4AiPuOUzk-N2"
      },
      "source": [
        "\n",
        "\n",
        "def VGG16(include_top=True,input_tensor=None, input_shape=(224,224,1),\n",
        "          pooling='max',classes=1000):\n",
        " \n",
        "    img_input = Input(shape=input_shape)\n",
        "\n",
        "    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv1')(img_input)\n",
        "    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv2')(x)\n",
        "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool')(x)\n",
        "\n",
        "    # Block 2\n",
        "    x = Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv1')(x)\n",
        "    x = Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv2')(x)\n",
        "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block2_pool')(x)\n",
        "\n",
        "    # Block 3\n",
        "    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv1')(x)\n",
        "    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv2')(x)\n",
        "    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv3')(x)\n",
        "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block3_pool')(x)\n",
        "\n",
        "    # Block 4\n",
        "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv1')(x)\n",
        "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv2')(x)\n",
        "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv3')(x)\n",
        "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block4_pool')(x)\n",
        "\n",
        "    # Block 5\n",
        "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv1')(x)\n",
        "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv2')(x)\n",
        "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv3')(x)\n",
        "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block5_pool')(x)\n",
        "\n",
        "    if include_top:\n",
        "        # Classification block\n",
        "        x = Flatten(name='flatten')(x)\n",
        "        x = Dense(4096, activation='relu', name='fc1')(x)\n",
        "        x = Dense(4096, activation='relu', name='fc2')(x)\n",
        "        x = Dense(classes, activation='softmax', name='predictions')(x)\n",
        "    else:\n",
        "        if pooling == 'avg':\n",
        "            x = GlobalAveragePooling2D()(x)\n",
        "        elif pooling == 'max':\n",
        "            x = GlobalMaxPooling2D()(x)\n",
        "\n",
        "    inputs = img_input\n",
        "    # Create model.\n",
        "    model = Model(inputs, x, name='vgg16')\n",
        "\n",
        "   \n",
        "    return model\n",
        "\n"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ViZAHjT3k-N7"
      },
      "source": [
        "#### 修改後"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T42WPkVGk-N8"
      },
      "source": [
        "def VGG16_Inception(include_top=True,input_tensor=None, input_shape=(224,224,1),\n",
        "          pooling='max',classes=1000):\n",
        " \n",
        "    '''修改模型'''\n",
        "    img_input = tf.keras.layers.Input(shape=input_shape)\n",
        "\n",
        "    #Block1\n",
        "    x = Conv2d_bn(img_input, 64, (3, 3), name='block1_conv1')\n",
        "    x = Conv2d_bn(x, 64, (3, 3), name='block1_conv2')\n",
        "    x = tf.keras.layers.MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool')(x)\n",
        "\n",
        "    # Block 2\n",
        "    x = Conv2d_bn(x, 128, (3, 3), name='block2_conv1')\n",
        "    x = Conv2d_bn(x, 128, (3, 3), name='block2_conv2')\n",
        "    x = tf.keras.layers.MaxPooling2D((2, 2), strides=(2, 2), name='block2_pool')(x)\n",
        "\n",
        "    # Block 3\n",
        "    x = InceptionV1_block(x, filter_spec_a, 3, name='InV1_block_1')\n",
        "    x = InceptionV1_block(x, filter_spec_a, 3, name='InV1_block_2')\n",
        "    x = InceptionV1_block(x, filter_spec_a, 3, name='InV1_block_3')\n",
        "    x = tf.keras.layers.MaxPooling2D((2, 2), strides=(2, 2), name='InceptionV1_block3_pool')(x)\n",
        "\n",
        "    # Block 4\n",
        "    x = Conv2d_bn(x, 512, (3, 3), name='block4_conv1')\n",
        "    x = Conv2d_bn(x, 512, (3, 3), name='block4_conv2')\n",
        "    x = Conv2d_bn(x, 512, (3, 3), name='block4_conv3')\n",
        "    x = tf.keras.layers.MaxPooling2D((2, 2), strides=(2, 2), name='block4_pool')(x)\n",
        "\n",
        "    # Block 5\n",
        "    x = InceptionV3_block(x, filter_spec_c, 3, name='InV3_block_1')\n",
        "    x = InceptionV3_block(x, filter_spec_c, 3, name='InV3_block_2')\n",
        "    x = InceptionV3_block(x, filter_spec_c, 3, name='InV3_block_3')\n",
        "    x = tf.keras.layers.MaxPooling2D((2, 2), strides=(2, 2), name='block5_pool')(x)\n",
        "\n",
        "    if include_top:\n",
        "        # Classification block\n",
        "        x = tf.keras.layers.Flatten(name='flatten')(x)\n",
        "        x = tf.keras.layers.Dense(4096, activation='relu', name='fc1')(x)\n",
        "        x = tf.keras.Dense(4096, activation='relu', name='fc2')(x)\n",
        "        x = tf.keras.layers.Dense(classes, activation='softmax', name='predictions')(x)\n",
        "    else:\n",
        "        if pooling == 'avg':\n",
        "            x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
        "        elif pooling == 'max':\n",
        "            x = tf.keras.layers.GlobalMaxPooling2D()(x)\n",
        "\n",
        "    # Create model.\n",
        "    model = tf.keras.Model(img_input, x, name='vgg16_inception')\n",
        "\n",
        "    return model\n",
        "\n"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LLoO093mk-OB",
        "outputId": "7861ead3-55ae-41e9-c184-88114044343b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model = VGG16_Inception(include_top=False)\n",
        "model.summary()"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"vgg16_inception\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            [(None, 224, 224, 1) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv1_conv (Conv2D)      (None, 224, 224, 64) 576         input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv1_bn (BatchNormaliza (None, 224, 224, 64) 192         block1_conv1_conv[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv1_act (Activation)   (None, 224, 224, 64) 0           block1_conv1_bn[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv2_conv (Conv2D)      (None, 224, 224, 64) 36864       block1_conv1_act[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv2_bn (BatchNormaliza (None, 224, 224, 64) 192         block1_conv2_conv[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv2_act (Activation)   (None, 224, 224, 64) 0           block1_conv2_bn[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block1_pool (MaxPooling2D)      (None, 112, 112, 64) 0           block1_conv2_act[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block2_conv1_conv (Conv2D)      (None, 112, 112, 128 73728       block1_pool[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block2_conv1_bn (BatchNormaliza (None, 112, 112, 128 384         block2_conv1_conv[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block2_conv1_act (Activation)   (None, 112, 112, 128 0           block2_conv1_bn[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block2_conv2_conv (Conv2D)      (None, 112, 112, 128 147456      block2_conv1_act[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block2_conv2_bn (BatchNormaliza (None, 112, 112, 128 384         block2_conv2_conv[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block2_conv2_act (Activation)   (None, 112, 112, 128 0           block2_conv2_bn[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block2_pool (MaxPooling2D)      (None, 56, 56, 128)  0           block2_conv2_act[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "InV1_block_1_Branch_1_conv (Con (None, 56, 56, 96)   12288       block2_pool[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "InV1_block_1_Branch_2_conv (Con (None, 56, 56, 16)   2048        block2_pool[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "InV1_block_1_Branch_1_bn (Batch (None, 56, 56, 96)   288         InV1_block_1_Branch_1_conv[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "InV1_block_1_Branch_2_bn (Batch (None, 56, 56, 16)   48          InV1_block_1_Branch_2_conv[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "InV1_block_1_Branch_1_act (Acti (None, 56, 56, 96)   0           InV1_block_1_Branch_1_bn[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "InV1_block_1_Branch_2_act (Acti (None, 56, 56, 16)   0           InV1_block_1_Branch_2_bn[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 56, 56, 128)  0           block2_pool[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "InV1_block_1_Branch_0_conv (Con (None, 56, 56, 64)   8192        block2_pool[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "InV1_block_1_Branch_1_1_conv (C (None, 56, 56, 128)  110592      InV1_block_1_Branch_1_act[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "InV1_block_1_Branch_2_1_conv (C (None, 56, 56, 32)   4608        InV1_block_1_Branch_2_act[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "InV1_block_1_Branch_3_conv (Con (None, 56, 56, 32)   4096        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "InV1_block_1_Branch_0_bn (Batch (None, 56, 56, 64)   192         InV1_block_1_Branch_0_conv[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "InV1_block_1_Branch_1_1_bn (Bat (None, 56, 56, 128)  384         InV1_block_1_Branch_1_1_conv[0][0\n",
            "__________________________________________________________________________________________________\n",
            "InV1_block_1_Branch_2_1_bn (Bat (None, 56, 56, 32)   96          InV1_block_1_Branch_2_1_conv[0][0\n",
            "__________________________________________________________________________________________________\n",
            "InV1_block_1_Branch_3_bn (Batch (None, 56, 56, 32)   96          InV1_block_1_Branch_3_conv[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "InV1_block_1_Branch_0_act (Acti (None, 56, 56, 64)   0           InV1_block_1_Branch_0_bn[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "InV1_block_1_Branch_1_1_act (Ac (None, 56, 56, 128)  0           InV1_block_1_Branch_1_1_bn[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "InV1_block_1_Branch_2_1_act (Ac (None, 56, 56, 32)   0           InV1_block_1_Branch_2_1_bn[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "InV1_block_1_Branch_3_act (Acti (None, 56, 56, 32)   0           InV1_block_1_Branch_3_bn[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "InV1_block_1_Concatenated (Conc (None, 56, 56, 256)  0           InV1_block_1_Branch_0_act[0][0]  \n",
            "                                                                 InV1_block_1_Branch_1_1_act[0][0]\n",
            "                                                                 InV1_block_1_Branch_2_1_act[0][0]\n",
            "                                                                 InV1_block_1_Branch_3_act[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "InV1_block_2_Branch_1_conv (Con (None, 56, 56, 96)   24576       InV1_block_1_Concatenated[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "InV1_block_2_Branch_2_conv (Con (None, 56, 56, 16)   4096        InV1_block_1_Concatenated[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "InV1_block_2_Branch_1_bn (Batch (None, 56, 56, 96)   288         InV1_block_2_Branch_1_conv[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "InV1_block_2_Branch_2_bn (Batch (None, 56, 56, 16)   48          InV1_block_2_Branch_2_conv[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "InV1_block_2_Branch_1_act (Acti (None, 56, 56, 96)   0           InV1_block_2_Branch_1_bn[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "InV1_block_2_Branch_2_act (Acti (None, 56, 56, 16)   0           InV1_block_2_Branch_2_bn[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 56, 56, 256)  0           InV1_block_1_Concatenated[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "InV1_block_2_Branch_0_conv (Con (None, 56, 56, 64)   16384       InV1_block_1_Concatenated[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "InV1_block_2_Branch_1_1_conv (C (None, 56, 56, 128)  110592      InV1_block_2_Branch_1_act[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "InV1_block_2_Branch_2_1_conv (C (None, 56, 56, 32)   4608        InV1_block_2_Branch_2_act[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "InV1_block_2_Branch_3_conv (Con (None, 56, 56, 32)   8192        max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "InV1_block_2_Branch_0_bn (Batch (None, 56, 56, 64)   192         InV1_block_2_Branch_0_conv[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "InV1_block_2_Branch_1_1_bn (Bat (None, 56, 56, 128)  384         InV1_block_2_Branch_1_1_conv[0][0\n",
            "__________________________________________________________________________________________________\n",
            "InV1_block_2_Branch_2_1_bn (Bat (None, 56, 56, 32)   96          InV1_block_2_Branch_2_1_conv[0][0\n",
            "__________________________________________________________________________________________________\n",
            "InV1_block_2_Branch_3_bn (Batch (None, 56, 56, 32)   96          InV1_block_2_Branch_3_conv[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "InV1_block_2_Branch_0_act (Acti (None, 56, 56, 64)   0           InV1_block_2_Branch_0_bn[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "InV1_block_2_Branch_1_1_act (Ac (None, 56, 56, 128)  0           InV1_block_2_Branch_1_1_bn[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "InV1_block_2_Branch_2_1_act (Ac (None, 56, 56, 32)   0           InV1_block_2_Branch_2_1_bn[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "InV1_block_2_Branch_3_act (Acti (None, 56, 56, 32)   0           InV1_block_2_Branch_3_bn[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "InV1_block_2_Concatenated (Conc (None, 56, 56, 256)  0           InV1_block_2_Branch_0_act[0][0]  \n",
            "                                                                 InV1_block_2_Branch_1_1_act[0][0]\n",
            "                                                                 InV1_block_2_Branch_2_1_act[0][0]\n",
            "                                                                 InV1_block_2_Branch_3_act[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "InV1_block_3_Branch_1_conv (Con (None, 56, 56, 96)   24576       InV1_block_2_Concatenated[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "InV1_block_3_Branch_2_conv (Con (None, 56, 56, 16)   4096        InV1_block_2_Concatenated[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "InV1_block_3_Branch_1_bn (Batch (None, 56, 56, 96)   288         InV1_block_3_Branch_1_conv[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "InV1_block_3_Branch_2_bn (Batch (None, 56, 56, 16)   48          InV1_block_3_Branch_2_conv[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "InV1_block_3_Branch_1_act (Acti (None, 56, 56, 96)   0           InV1_block_3_Branch_1_bn[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "InV1_block_3_Branch_2_act (Acti (None, 56, 56, 16)   0           InV1_block_3_Branch_2_bn[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2D)  (None, 56, 56, 256)  0           InV1_block_2_Concatenated[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "InV1_block_3_Branch_0_conv (Con (None, 56, 56, 64)   16384       InV1_block_2_Concatenated[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "InV1_block_3_Branch_1_1_conv (C (None, 56, 56, 128)  110592      InV1_block_3_Branch_1_act[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "InV1_block_3_Branch_2_1_conv (C (None, 56, 56, 32)   4608        InV1_block_3_Branch_2_act[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "InV1_block_3_Branch_3_conv (Con (None, 56, 56, 32)   8192        max_pooling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "InV1_block_3_Branch_0_bn (Batch (None, 56, 56, 64)   192         InV1_block_3_Branch_0_conv[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "InV1_block_3_Branch_1_1_bn (Bat (None, 56, 56, 128)  384         InV1_block_3_Branch_1_1_conv[0][0\n",
            "__________________________________________________________________________________________________\n",
            "InV1_block_3_Branch_2_1_bn (Bat (None, 56, 56, 32)   96          InV1_block_3_Branch_2_1_conv[0][0\n",
            "__________________________________________________________________________________________________\n",
            "InV1_block_3_Branch_3_bn (Batch (None, 56, 56, 32)   96          InV1_block_3_Branch_3_conv[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "InV1_block_3_Branch_0_act (Acti (None, 56, 56, 64)   0           InV1_block_3_Branch_0_bn[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "InV1_block_3_Branch_1_1_act (Ac (None, 56, 56, 128)  0           InV1_block_3_Branch_1_1_bn[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "InV1_block_3_Branch_2_1_act (Ac (None, 56, 56, 32)   0           InV1_block_3_Branch_2_1_bn[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "InV1_block_3_Branch_3_act (Acti (None, 56, 56, 32)   0           InV1_block_3_Branch_3_bn[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "InV1_block_3_Concatenated (Conc (None, 56, 56, 256)  0           InV1_block_3_Branch_0_act[0][0]  \n",
            "                                                                 InV1_block_3_Branch_1_1_act[0][0]\n",
            "                                                                 InV1_block_3_Branch_2_1_act[0][0]\n",
            "                                                                 InV1_block_3_Branch_3_act[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "InceptionV1_block3_pool (MaxPoo (None, 28, 28, 256)  0           InV1_block_3_Concatenated[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "block4_conv1_conv (Conv2D)      (None, 28, 28, 512)  1179648     InceptionV1_block3_pool[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block4_conv1_bn (BatchNormaliza (None, 28, 28, 512)  1536        block4_conv1_conv[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block4_conv1_act (Activation)   (None, 28, 28, 512)  0           block4_conv1_bn[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block4_conv2_conv (Conv2D)      (None, 28, 28, 512)  2359296     block4_conv1_act[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block4_conv2_bn (BatchNormaliza (None, 28, 28, 512)  1536        block4_conv2_conv[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block4_conv2_act (Activation)   (None, 28, 28, 512)  0           block4_conv2_bn[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block4_conv3_conv (Conv2D)      (None, 28, 28, 512)  2359296     block4_conv2_act[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block4_conv3_bn (BatchNormaliza (None, 28, 28, 512)  1536        block4_conv3_conv[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block4_conv3_act (Activation)   (None, 28, 28, 512)  0           block4_conv3_bn[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block4_pool (MaxPooling2D)      (None, 14, 14, 512)  0           block4_conv3_act[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "InV3_block_1_Branch_1_conv (Con (None, 14, 14, 192)  98304       block4_pool[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "InV3_block_1_Branch_2_conv (Con (None, 14, 14, 32)   16384       block4_pool[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "InV3_block_1_Branch_1_bn (Batch (None, 14, 14, 192)  576         InV3_block_1_Branch_1_conv[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "InV3_block_1_Branch_2_bn (Batch (None, 14, 14, 32)   96          InV3_block_1_Branch_2_conv[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "InV3_block_1_Branch_1_act (Acti (None, 14, 14, 192)  0           InV3_block_1_Branch_1_bn[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "InV3_block_1_Branch_2_act (Acti (None, 14, 14, 32)   0           InV3_block_1_Branch_2_bn[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "InV3_block_1_Branch_1_1_conv (C (None, 14, 14, 256)  147456      InV3_block_1_Branch_1_act[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "InV3_block_1_Branch_2_1_conv (C (None, 14, 14, 64)   6144        InV3_block_1_Branch_2_act[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "InV3_block_1_Branch_1_1_bn (Bat (None, 14, 14, 256)  768         InV3_block_1_Branch_1_1_conv[0][0\n",
            "__________________________________________________________________________________________________\n",
            "InV3_block_1_Branch_2_1_bn (Bat (None, 14, 14, 64)   192         InV3_block_1_Branch_2_1_conv[0][0\n",
            "__________________________________________________________________________________________________\n",
            "InV3_block_1_Branch_1_1_act (Ac (None, 14, 14, 256)  0           InV3_block_1_Branch_1_1_bn[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "InV3_block_1_Branch_2_1_act (Ac (None, 14, 14, 64)   0           InV3_block_1_Branch_2_1_bn[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2D)  (None, 14, 14, 512)  0           block4_pool[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "InV3_block_1_Branch_0_conv (Con (None, 14, 14, 128)  65536       block4_pool[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "InV3_block_1_Branch_1_2_conv (C (None, 14, 14, 256)  196608      InV3_block_1_Branch_1_1_act[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "InV3_block_1_Branch_2_2_conv (C (None, 14, 14, 64)   12288       InV3_block_1_Branch_2_1_act[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "InV3_block_1_Branch_3_conv (Con (None, 14, 14, 64)   32768       max_pooling2d_4[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "InV3_block_1_Branch_0_bn (Batch (None, 14, 14, 128)  384         InV3_block_1_Branch_0_conv[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "InV3_block_1_Branch_1_2_bn (Bat (None, 14, 14, 256)  768         InV3_block_1_Branch_1_2_conv[0][0\n",
            "__________________________________________________________________________________________________\n",
            "InV3_block_1_Branch_2_2_bn (Bat (None, 14, 14, 64)   192         InV3_block_1_Branch_2_2_conv[0][0\n",
            "__________________________________________________________________________________________________\n",
            "InV3_block_1_Branch_3_bn (Batch (None, 14, 14, 64)   192         InV3_block_1_Branch_3_conv[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "InV3_block_1_Branch_0_act (Acti (None, 14, 14, 128)  0           InV3_block_1_Branch_0_bn[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "InV3_block_1_Branch_1_2_act (Ac (None, 14, 14, 256)  0           InV3_block_1_Branch_1_2_bn[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "InV3_block_1_Branch_2_2_act (Ac (None, 14, 14, 64)   0           InV3_block_1_Branch_2_2_bn[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "InV3_block_1_Branch_3_act (Acti (None, 14, 14, 64)   0           InV3_block_1_Branch_3_bn[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "InV3_block_1_Concatenated (Conc (None, 14, 14, 512)  0           InV3_block_1_Branch_0_act[0][0]  \n",
            "                                                                 InV3_block_1_Branch_1_2_act[0][0]\n",
            "                                                                 InV3_block_1_Branch_2_2_act[0][0]\n",
            "                                                                 InV3_block_1_Branch_3_act[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "InV3_block_2_Branch_1_conv (Con (None, 14, 14, 192)  98304       InV3_block_1_Concatenated[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "InV3_block_2_Branch_2_conv (Con (None, 14, 14, 32)   16384       InV3_block_1_Concatenated[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "InV3_block_2_Branch_1_bn (Batch (None, 14, 14, 192)  576         InV3_block_2_Branch_1_conv[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "InV3_block_2_Branch_2_bn (Batch (None, 14, 14, 32)   96          InV3_block_2_Branch_2_conv[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "InV3_block_2_Branch_1_act (Acti (None, 14, 14, 192)  0           InV3_block_2_Branch_1_bn[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "InV3_block_2_Branch_2_act (Acti (None, 14, 14, 32)   0           InV3_block_2_Branch_2_bn[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "InV3_block_2_Branch_1_1_conv (C (None, 14, 14, 256)  147456      InV3_block_2_Branch_1_act[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "InV3_block_2_Branch_2_1_conv (C (None, 14, 14, 64)   6144        InV3_block_2_Branch_2_act[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "InV3_block_2_Branch_1_1_bn (Bat (None, 14, 14, 256)  768         InV3_block_2_Branch_1_1_conv[0][0\n",
            "__________________________________________________________________________________________________\n",
            "InV3_block_2_Branch_2_1_bn (Bat (None, 14, 14, 64)   192         InV3_block_2_Branch_2_1_conv[0][0\n",
            "__________________________________________________________________________________________________\n",
            "InV3_block_2_Branch_1_1_act (Ac (None, 14, 14, 256)  0           InV3_block_2_Branch_1_1_bn[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "InV3_block_2_Branch_2_1_act (Ac (None, 14, 14, 64)   0           InV3_block_2_Branch_2_1_bn[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2D)  (None, 14, 14, 512)  0           InV3_block_1_Concatenated[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "InV3_block_2_Branch_0_conv (Con (None, 14, 14, 128)  65536       InV3_block_1_Concatenated[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "InV3_block_2_Branch_1_2_conv (C (None, 14, 14, 256)  196608      InV3_block_2_Branch_1_1_act[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "InV3_block_2_Branch_2_2_conv (C (None, 14, 14, 64)   12288       InV3_block_2_Branch_2_1_act[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "InV3_block_2_Branch_3_conv (Con (None, 14, 14, 64)   32768       max_pooling2d_5[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "InV3_block_2_Branch_0_bn (Batch (None, 14, 14, 128)  384         InV3_block_2_Branch_0_conv[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "InV3_block_2_Branch_1_2_bn (Bat (None, 14, 14, 256)  768         InV3_block_2_Branch_1_2_conv[0][0\n",
            "__________________________________________________________________________________________________\n",
            "InV3_block_2_Branch_2_2_bn (Bat (None, 14, 14, 64)   192         InV3_block_2_Branch_2_2_conv[0][0\n",
            "__________________________________________________________________________________________________\n",
            "InV3_block_2_Branch_3_bn (Batch (None, 14, 14, 64)   192         InV3_block_2_Branch_3_conv[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "InV3_block_2_Branch_0_act (Acti (None, 14, 14, 128)  0           InV3_block_2_Branch_0_bn[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "InV3_block_2_Branch_1_2_act (Ac (None, 14, 14, 256)  0           InV3_block_2_Branch_1_2_bn[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "InV3_block_2_Branch_2_2_act (Ac (None, 14, 14, 64)   0           InV3_block_2_Branch_2_2_bn[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "InV3_block_2_Branch_3_act (Acti (None, 14, 14, 64)   0           InV3_block_2_Branch_3_bn[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "InV3_block_2_Concatenated (Conc (None, 14, 14, 512)  0           InV3_block_2_Branch_0_act[0][0]  \n",
            "                                                                 InV3_block_2_Branch_1_2_act[0][0]\n",
            "                                                                 InV3_block_2_Branch_2_2_act[0][0]\n",
            "                                                                 InV3_block_2_Branch_3_act[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "InV3_block_3_Branch_1_conv (Con (None, 14, 14, 192)  98304       InV3_block_2_Concatenated[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "InV3_block_3_Branch_2_conv (Con (None, 14, 14, 32)   16384       InV3_block_2_Concatenated[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "InV3_block_3_Branch_1_bn (Batch (None, 14, 14, 192)  576         InV3_block_3_Branch_1_conv[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "InV3_block_3_Branch_2_bn (Batch (None, 14, 14, 32)   96          InV3_block_3_Branch_2_conv[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "InV3_block_3_Branch_1_act (Acti (None, 14, 14, 192)  0           InV3_block_3_Branch_1_bn[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "InV3_block_3_Branch_2_act (Acti (None, 14, 14, 32)   0           InV3_block_3_Branch_2_bn[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "InV3_block_3_Branch_1_1_conv (C (None, 14, 14, 256)  147456      InV3_block_3_Branch_1_act[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "InV3_block_3_Branch_2_1_conv (C (None, 14, 14, 64)   6144        InV3_block_3_Branch_2_act[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "InV3_block_3_Branch_1_1_bn (Bat (None, 14, 14, 256)  768         InV3_block_3_Branch_1_1_conv[0][0\n",
            "__________________________________________________________________________________________________\n",
            "InV3_block_3_Branch_2_1_bn (Bat (None, 14, 14, 64)   192         InV3_block_3_Branch_2_1_conv[0][0\n",
            "__________________________________________________________________________________________________\n",
            "InV3_block_3_Branch_1_1_act (Ac (None, 14, 14, 256)  0           InV3_block_3_Branch_1_1_bn[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "InV3_block_3_Branch_2_1_act (Ac (None, 14, 14, 64)   0           InV3_block_3_Branch_2_1_bn[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2D)  (None, 14, 14, 512)  0           InV3_block_2_Concatenated[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "InV3_block_3_Branch_0_conv (Con (None, 14, 14, 128)  65536       InV3_block_2_Concatenated[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "InV3_block_3_Branch_1_2_conv (C (None, 14, 14, 256)  196608      InV3_block_3_Branch_1_1_act[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "InV3_block_3_Branch_2_2_conv (C (None, 14, 14, 64)   12288       InV3_block_3_Branch_2_1_act[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "InV3_block_3_Branch_3_conv (Con (None, 14, 14, 64)   32768       max_pooling2d_6[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "InV3_block_3_Branch_0_bn (Batch (None, 14, 14, 128)  384         InV3_block_3_Branch_0_conv[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "InV3_block_3_Branch_1_2_bn (Bat (None, 14, 14, 256)  768         InV3_block_3_Branch_1_2_conv[0][0\n",
            "__________________________________________________________________________________________________\n",
            "InV3_block_3_Branch_2_2_bn (Bat (None, 14, 14, 64)   192         InV3_block_3_Branch_2_2_conv[0][0\n",
            "__________________________________________________________________________________________________\n",
            "InV3_block_3_Branch_3_bn (Batch (None, 14, 14, 64)   192         InV3_block_3_Branch_3_conv[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "InV3_block_3_Branch_0_act (Acti (None, 14, 14, 128)  0           InV3_block_3_Branch_0_bn[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "InV3_block_3_Branch_1_2_act (Ac (None, 14, 14, 256)  0           InV3_block_3_Branch_1_2_bn[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "InV3_block_3_Branch_2_2_act (Ac (None, 14, 14, 64)   0           InV3_block_3_Branch_2_2_bn[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "InV3_block_3_Branch_3_act (Acti (None, 14, 14, 64)   0           InV3_block_3_Branch_3_bn[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "InV3_block_3_Concatenated (Conc (None, 14, 14, 512)  0           InV3_block_3_Branch_0_act[0][0]  \n",
            "                                                                 InV3_block_3_Branch_1_2_act[0][0]\n",
            "                                                                 InV3_block_3_Branch_2_2_act[0][0]\n",
            "                                                                 InV3_block_3_Branch_3_act[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "block5_pool (MaxPooling2D)      (None, 7, 7, 512)    0           InV3_block_3_Concatenated[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling2d (GlobalMax (None, 512)          0           block5_pool[0][0]                \n",
            "==================================================================================================\n",
            "Total params: 8,380,624\n",
            "Trainable params: 8,368,240\n",
            "Non-trainable params: 12,384\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AbABniRyh01J",
        "outputId": "094fda38-a99c-4320-cb01-24f92b23f8db",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "input_map = 512\n",
        "#branch0\n",
        "b0 = input_map*1*128 \n",
        "\n",
        "#branch1\n",
        "b1 = (input_map*1*192, 192*3*256, 256*3*256)\n",
        "\n",
        "#branch2\n",
        "b2 = (input_map*1*32, 32*3*64, 64*3*64) \n",
        "\n",
        "#branch3\n",
        "b3 = (input_map*1*64)\n",
        "print(f'b0:{b0}, b1:{b1}, b2:{b2}, b3:{b3}')\n",
        "filter_spec_c = ((128, ), (192, 256), (32, 64), (64,))"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "b0:65536, b1:(98304, 147456, 196608), b2:(16384, 6144, 12288), b3:32768\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2z7qWpNAnMBd",
        "outputId": "6277ffa4-ac27-471d-a6c5-7a1fc08d3831",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "input_map = 256\n",
        "#branch0\n",
        "b0 = input_map*1*64 \n",
        "\n",
        "#branch1\n",
        "b1 = (input_map*1*96, 96*9*128, 128*9*128)\n",
        "\n",
        "#branch2\n",
        "b2 = (input_map*1*16, 16*9*32, 32*9*32) \n",
        "\n",
        "#branch3\n",
        "b3 = (input_map*1*32)\n",
        "print(f'b0:{b0}, b1:{b1}, b2:{b2}, b3:{b3}')\n",
        "filter_spec_b = ((64, ), (96,), (16,), (32,))"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "b0:16384, b1:(24576, 110592, 147456), b2:(4096, 4608, 9216), b3:8192\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4RUR8XJZT54Y",
        "outputId": "6be90b7e-9a07-42c9-d4d0-e45fa32e0d04",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "input_map = 128\n",
        "#branch0\n",
        "b0 = input_map*1*64 \n",
        "\n",
        "#branch1\n",
        "b1 = (input_map*1*96, 96*9*128, 128*9*128)\n",
        "\n",
        "#branch2\n",
        "b2 = (input_map*1*16, 16*9*32, 32*9*32) \n",
        "\n",
        "#branch3\n",
        "b3 = (input_map*1*32)\n",
        "print(f'b0:{b0}, b1:{b1}, b2:{b2}, b3:{b3}')\n",
        "filter_spec_a = ((64, ), (96, 128), (16, 32), (32,))"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "b0:8192, b1:(12288, 110592, 147456), b2:(2048, 4608, 9216), b3:4096\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}