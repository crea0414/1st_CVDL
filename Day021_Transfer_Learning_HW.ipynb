{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "Day021_Transfer Learning_HW.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/crea0414/1st_CVDL/blob/master/Day021_Transfer_Learning_HW.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TCDe31nrVw4c"
      },
      "source": [
        "## 『本次練習內容』\n",
        "#### 使用Xception backbone做 Trnasfer Learning\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6NAmn3MVVw4g"
      },
      "source": [
        "## 『本次練習目的』\n",
        "  #### 了解如何使用Transfer Learning\n",
        "  #### 了解Transfer Learning的優點，可以觀察模型收斂速度"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fffUzubsVw4i"
      },
      "source": [
        "##### 可以自行嘗試多種架構"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ne4UHhgBZOVr",
        "outputId": "6b106ea2-1467-4dd7-96de-daffd4534b19",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.__version__"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.3.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sr3CpDvSuIBa"
      },
      "source": [
        "## Xception"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oITMftxKVw4m",
        "outputId": "5232a42b-0551-4f93-9fae-9678f24e1fcb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "tf.keras.backend.clear_session()\n",
        "\n",
        "input_tensor = tf.keras.layers.Input(shape=(32, 32, 3))\n",
        "#include top 決定要不要加入 fully Connected Layer\n",
        "'''Xception 架構'''\n",
        "\"\"\"自行填入\"\"\"\n",
        "model = tf.keras.applications.Xception(include_top=False, input_tensor=input_tensor)\n",
        "'''Resnet 50 架構'''\n",
        "#model=tf.keras.applications.ResNet50V2(include_top=False, weights='imagenet',\n",
        "#                                    input_tensor=input_tensor,\n",
        "                                    #pooling=None, classes=10)\n",
        "#                                    )\n",
        "model.summary()\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/xception/xception_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "83689472/83683744 [==============================] - 1s 0us/step\n",
            "Model: \"xception\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv1 (Conv2D)           (None, 15, 15, 32)   864         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv1_bn (BatchNormaliza (None, 15, 15, 32)   128         block1_conv1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv1_act (Activation)   (None, 15, 15, 32)   0           block1_conv1_bn[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv2 (Conv2D)           (None, 13, 13, 64)   18432       block1_conv1_act[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv2_bn (BatchNormaliza (None, 13, 13, 64)   256         block1_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv2_act (Activation)   (None, 13, 13, 64)   0           block1_conv2_bn[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block2_sepconv1 (SeparableConv2 (None, 13, 13, 128)  8768        block1_conv2_act[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block2_sepconv1_bn (BatchNormal (None, 13, 13, 128)  512         block2_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block2_sepconv2_act (Activation (None, 13, 13, 128)  0           block2_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block2_sepconv2 (SeparableConv2 (None, 13, 13, 128)  17536       block2_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block2_sepconv2_bn (BatchNormal (None, 13, 13, 128)  512         block2_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 7, 7, 128)    8192        block1_conv2_act[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block2_pool (MaxPooling2D)      (None, 7, 7, 128)    0           block2_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 7, 7, 128)    512         conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "add (Add)                       (None, 7, 7, 128)    0           block2_pool[0][0]                \n",
            "                                                                 batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block3_sepconv1_act (Activation (None, 7, 7, 128)    0           add[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "block3_sepconv1 (SeparableConv2 (None, 7, 7, 256)    33920       block3_sepconv1_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block3_sepconv1_bn (BatchNormal (None, 7, 7, 256)    1024        block3_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block3_sepconv2_act (Activation (None, 7, 7, 256)    0           block3_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block3_sepconv2 (SeparableConv2 (None, 7, 7, 256)    67840       block3_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block3_sepconv2_bn (BatchNormal (None, 7, 7, 256)    1024        block3_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 4, 4, 256)    32768       add[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "block3_pool (MaxPooling2D)      (None, 4, 4, 256)    0           block3_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 4, 4, 256)    1024        conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 4, 4, 256)    0           block3_pool[0][0]                \n",
            "                                                                 batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "block4_sepconv1_act (Activation (None, 4, 4, 256)    0           add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block4_sepconv1 (SeparableConv2 (None, 4, 4, 728)    188672      block4_sepconv1_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block4_sepconv1_bn (BatchNormal (None, 4, 4, 728)    2912        block4_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block4_sepconv2_act (Activation (None, 4, 4, 728)    0           block4_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block4_sepconv2 (SeparableConv2 (None, 4, 4, 728)    536536      block4_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block4_sepconv2_bn (BatchNormal (None, 4, 4, 728)    2912        block4_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 2, 2, 728)    186368      add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block4_pool (MaxPooling2D)      (None, 2, 2, 728)    0           block4_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 2, 2, 728)    2912        conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 2, 2, 728)    0           block4_pool[0][0]                \n",
            "                                                                 batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv1_act (Activation (None, 2, 2, 728)    0           add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv1 (SeparableConv2 (None, 2, 2, 728)    536536      block5_sepconv1_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv1_bn (BatchNormal (None, 2, 2, 728)    2912        block5_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv2_act (Activation (None, 2, 2, 728)    0           block5_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv2 (SeparableConv2 (None, 2, 2, 728)    536536      block5_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv2_bn (BatchNormal (None, 2, 2, 728)    2912        block5_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv3_act (Activation (None, 2, 2, 728)    0           block5_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv3 (SeparableConv2 (None, 2, 2, 728)    536536      block5_sepconv3_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv3_bn (BatchNormal (None, 2, 2, 728)    2912        block5_sepconv3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 2, 2, 728)    0           block5_sepconv3_bn[0][0]         \n",
            "                                                                 add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv1_act (Activation (None, 2, 2, 728)    0           add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv1 (SeparableConv2 (None, 2, 2, 728)    536536      block6_sepconv1_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv1_bn (BatchNormal (None, 2, 2, 728)    2912        block6_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv2_act (Activation (None, 2, 2, 728)    0           block6_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv2 (SeparableConv2 (None, 2, 2, 728)    536536      block6_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv2_bn (BatchNormal (None, 2, 2, 728)    2912        block6_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv3_act (Activation (None, 2, 2, 728)    0           block6_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv3 (SeparableConv2 (None, 2, 2, 728)    536536      block6_sepconv3_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv3_bn (BatchNormal (None, 2, 2, 728)    2912        block6_sepconv3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, 2, 2, 728)    0           block6_sepconv3_bn[0][0]         \n",
            "                                                                 add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv1_act (Activation (None, 2, 2, 728)    0           add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv1 (SeparableConv2 (None, 2, 2, 728)    536536      block7_sepconv1_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv1_bn (BatchNormal (None, 2, 2, 728)    2912        block7_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv2_act (Activation (None, 2, 2, 728)    0           block7_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv2 (SeparableConv2 (None, 2, 2, 728)    536536      block7_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv2_bn (BatchNormal (None, 2, 2, 728)    2912        block7_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv3_act (Activation (None, 2, 2, 728)    0           block7_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv3 (SeparableConv2 (None, 2, 2, 728)    536536      block7_sepconv3_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv3_bn (BatchNormal (None, 2, 2, 728)    2912        block7_sepconv3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, 2, 2, 728)    0           block7_sepconv3_bn[0][0]         \n",
            "                                                                 add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv1_act (Activation (None, 2, 2, 728)    0           add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv1 (SeparableConv2 (None, 2, 2, 728)    536536      block8_sepconv1_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv1_bn (BatchNormal (None, 2, 2, 728)    2912        block8_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv2_act (Activation (None, 2, 2, 728)    0           block8_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv2 (SeparableConv2 (None, 2, 2, 728)    536536      block8_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv2_bn (BatchNormal (None, 2, 2, 728)    2912        block8_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv3_act (Activation (None, 2, 2, 728)    0           block8_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv3 (SeparableConv2 (None, 2, 2, 728)    536536      block8_sepconv3_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv3_bn (BatchNormal (None, 2, 2, 728)    2912        block8_sepconv3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "add_6 (Add)                     (None, 2, 2, 728)    0           block8_sepconv3_bn[0][0]         \n",
            "                                                                 add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv1_act (Activation (None, 2, 2, 728)    0           add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv1 (SeparableConv2 (None, 2, 2, 728)    536536      block9_sepconv1_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv1_bn (BatchNormal (None, 2, 2, 728)    2912        block9_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv2_act (Activation (None, 2, 2, 728)    0           block9_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv2 (SeparableConv2 (None, 2, 2, 728)    536536      block9_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv2_bn (BatchNormal (None, 2, 2, 728)    2912        block9_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv3_act (Activation (None, 2, 2, 728)    0           block9_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv3 (SeparableConv2 (None, 2, 2, 728)    536536      block9_sepconv3_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv3_bn (BatchNormal (None, 2, 2, 728)    2912        block9_sepconv3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "add_7 (Add)                     (None, 2, 2, 728)    0           block9_sepconv3_bn[0][0]         \n",
            "                                                                 add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv1_act (Activatio (None, 2, 2, 728)    0           add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv1 (SeparableConv (None, 2, 2, 728)    536536      block10_sepconv1_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv1_bn (BatchNorma (None, 2, 2, 728)    2912        block10_sepconv1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv2_act (Activatio (None, 2, 2, 728)    0           block10_sepconv1_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv2 (SeparableConv (None, 2, 2, 728)    536536      block10_sepconv2_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv2_bn (BatchNorma (None, 2, 2, 728)    2912        block10_sepconv2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv3_act (Activatio (None, 2, 2, 728)    0           block10_sepconv2_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv3 (SeparableConv (None, 2, 2, 728)    536536      block10_sepconv3_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv3_bn (BatchNorma (None, 2, 2, 728)    2912        block10_sepconv3[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "add_8 (Add)                     (None, 2, 2, 728)    0           block10_sepconv3_bn[0][0]        \n",
            "                                                                 add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv1_act (Activatio (None, 2, 2, 728)    0           add_8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv1 (SeparableConv (None, 2, 2, 728)    536536      block11_sepconv1_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv1_bn (BatchNorma (None, 2, 2, 728)    2912        block11_sepconv1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv2_act (Activatio (None, 2, 2, 728)    0           block11_sepconv1_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv2 (SeparableConv (None, 2, 2, 728)    536536      block11_sepconv2_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv2_bn (BatchNorma (None, 2, 2, 728)    2912        block11_sepconv2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv3_act (Activatio (None, 2, 2, 728)    0           block11_sepconv2_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv3 (SeparableConv (None, 2, 2, 728)    536536      block11_sepconv3_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv3_bn (BatchNorma (None, 2, 2, 728)    2912        block11_sepconv3[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "add_9 (Add)                     (None, 2, 2, 728)    0           block11_sepconv3_bn[0][0]        \n",
            "                                                                 add_8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv1_act (Activatio (None, 2, 2, 728)    0           add_9[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv1 (SeparableConv (None, 2, 2, 728)    536536      block12_sepconv1_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv1_bn (BatchNorma (None, 2, 2, 728)    2912        block12_sepconv1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv2_act (Activatio (None, 2, 2, 728)    0           block12_sepconv1_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv2 (SeparableConv (None, 2, 2, 728)    536536      block12_sepconv2_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv2_bn (BatchNorma (None, 2, 2, 728)    2912        block12_sepconv2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv3_act (Activatio (None, 2, 2, 728)    0           block12_sepconv2_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv3 (SeparableConv (None, 2, 2, 728)    536536      block12_sepconv3_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv3_bn (BatchNorma (None, 2, 2, 728)    2912        block12_sepconv3[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "add_10 (Add)                    (None, 2, 2, 728)    0           block12_sepconv3_bn[0][0]        \n",
            "                                                                 add_9[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block13_sepconv1_act (Activatio (None, 2, 2, 728)    0           add_10[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block13_sepconv1 (SeparableConv (None, 2, 2, 728)    536536      block13_sepconv1_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block13_sepconv1_bn (BatchNorma (None, 2, 2, 728)    2912        block13_sepconv1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block13_sepconv2_act (Activatio (None, 2, 2, 728)    0           block13_sepconv1_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block13_sepconv2 (SeparableConv (None, 2, 2, 1024)   752024      block13_sepconv2_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block13_sepconv2_bn (BatchNorma (None, 2, 2, 1024)   4096        block13_sepconv2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 1, 1, 1024)   745472      add_10[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block13_pool (MaxPooling2D)     (None, 1, 1, 1024)   0           block13_sepconv2_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 1, 1, 1024)   4096        conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_11 (Add)                    (None, 1, 1, 1024)   0           block13_pool[0][0]               \n",
            "                                                                 batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "block14_sepconv1 (SeparableConv (None, 1, 1, 1536)   1582080     add_11[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block14_sepconv1_bn (BatchNorma (None, 1, 1, 1536)   6144        block14_sepconv1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block14_sepconv1_act (Activatio (None, 1, 1, 1536)   0           block14_sepconv1_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block14_sepconv2 (SeparableConv (None, 1, 1, 2048)   3159552     block14_sepconv1_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block14_sepconv2_bn (BatchNorma (None, 1, 1, 2048)   8192        block14_sepconv2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block14_sepconv2_act (Activatio (None, 1, 1, 2048)   0           block14_sepconv2_bn[0][0]        \n",
            "==================================================================================================\n",
            "Total params: 20,861,480\n",
            "Trainable params: 20,806,952\n",
            "Non-trainable params: 54,528\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MoGLvKd9aHbv",
        "outputId": "f43919fd-3e38-4657-ef31-d8cfe5d11933",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print('Model深度：', len(model.layers))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model深度： 132\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PVeHAX6kVw5F"
      },
      "source": [
        "## 鎖定特定幾層不要更新權重"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "va627yspVw5H",
        "outputId": "b6e53630-b629-45fb-e2a4-02b25c97b94e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_flag = False\n",
        "for idx, layer in enumerate(model.layers):\n",
        "    if layer.name == 'block5_sepconv1_act': train_flag = True, print(idx+1)\n",
        "    if train_flag: layer.trainable = True\n",
        "    else: layer.trainable = False"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "37\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bv6Cofo6Vw40"
      },
      "source": [
        "## 添加層數"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hDz-FQXUVw42",
        "outputId": "452cba06-febe-44d4-b835-71750182ac15",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x = model.get_layer('block5_sepconv1_act').output\n",
        "\n",
        "'''可以參考Cifar10實作章節,自行填入'''\n",
        "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
        "x = tf.keras.layers.BatchNormalization()(x)\n",
        "x = tf.keras.layers.Dropout(rate=0.1)(x)\n",
        "x = tf.keras.layers.Dense(512,\n",
        "                          kernel_initializer='he_normal', \n",
        "                          kernel_regularizer=tf.keras.regularizers.L2(l2=0.01/2)\n",
        "                          )(x)\n",
        "x = tf.keras.layers.BatchNormalization()(x)\n",
        "x = tf.keras.layers.Activation('relu')(x)\n",
        "#x = tf.keras.layers.Dense(512)(x)\n",
        "#x = tf.keras.layers.BatchNormalization()(x)\n",
        "#x = tf.keras.layers.Activation('relu')(x)\n",
        "x = tf.keras.layers.Dropout(rate=0.1)(x)\n",
        "predictions = tf.keras.layers.Dense(10, activation='softmax', \n",
        "                                    kernel_initializer='he_normal', \n",
        "                                    kernel_regularizer=tf.keras.regularizers.L2(l2=0.01/2))(x)\n",
        "model = tf.keras.Model(inputs=model.input, outputs=predictions)\n",
        "print('Model深度：', len(model.layers))\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model深度： 45\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ysvcxT7kj-Dt",
        "outputId": "c893e6e9-9416-4ef4-8266-933713cbdbab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv1 (Conv2D)           (None, 15, 15, 32)   864         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv1_bn (BatchNormaliza (None, 15, 15, 32)   128         block1_conv1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv1_act (Activation)   (None, 15, 15, 32)   0           block1_conv1_bn[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv2 (Conv2D)           (None, 13, 13, 64)   18432       block1_conv1_act[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv2_bn (BatchNormaliza (None, 13, 13, 64)   256         block1_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv2_act (Activation)   (None, 13, 13, 64)   0           block1_conv2_bn[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block2_sepconv1 (SeparableConv2 (None, 13, 13, 128)  8768        block1_conv2_act[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block2_sepconv1_bn (BatchNormal (None, 13, 13, 128)  512         block2_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block2_sepconv2_act (Activation (None, 13, 13, 128)  0           block2_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block2_sepconv2 (SeparableConv2 (None, 13, 13, 128)  17536       block2_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block2_sepconv2_bn (BatchNormal (None, 13, 13, 128)  512         block2_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 7, 7, 128)    8192        block1_conv2_act[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block2_pool (MaxPooling2D)      (None, 7, 7, 128)    0           block2_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 7, 7, 128)    512         conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "add (Add)                       (None, 7, 7, 128)    0           block2_pool[0][0]                \n",
            "                                                                 batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block3_sepconv1_act (Activation (None, 7, 7, 128)    0           add[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "block3_sepconv1 (SeparableConv2 (None, 7, 7, 256)    33920       block3_sepconv1_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block3_sepconv1_bn (BatchNormal (None, 7, 7, 256)    1024        block3_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block3_sepconv2_act (Activation (None, 7, 7, 256)    0           block3_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block3_sepconv2 (SeparableConv2 (None, 7, 7, 256)    67840       block3_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block3_sepconv2_bn (BatchNormal (None, 7, 7, 256)    1024        block3_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 4, 4, 256)    32768       add[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "block3_pool (MaxPooling2D)      (None, 4, 4, 256)    0           block3_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 4, 4, 256)    1024        conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 4, 4, 256)    0           block3_pool[0][0]                \n",
            "                                                                 batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "block4_sepconv1_act (Activation (None, 4, 4, 256)    0           add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block4_sepconv1 (SeparableConv2 (None, 4, 4, 728)    188672      block4_sepconv1_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block4_sepconv1_bn (BatchNormal (None, 4, 4, 728)    2912        block4_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block4_sepconv2_act (Activation (None, 4, 4, 728)    0           block4_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block4_sepconv2 (SeparableConv2 (None, 4, 4, 728)    536536      block4_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block4_sepconv2_bn (BatchNormal (None, 4, 4, 728)    2912        block4_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 2, 2, 728)    186368      add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block4_pool (MaxPooling2D)      (None, 2, 2, 728)    0           block4_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 2, 2, 728)    2912        conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 2, 2, 728)    0           block4_pool[0][0]                \n",
            "                                                                 batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv1_act (Activation (None, 2, 2, 728)    0           add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d (Globa (None, 728)          0           block5_sepconv1_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 728)          2912        global_average_pooling2d[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 728)          0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 512)          373248      dropout[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 512)          2048        dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 512)          0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 512)          0           activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 10)           5130        dropout_1[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 1,496,962\n",
            "Trainable params: 380,858\n",
            "Non-trainable params: 1,116,104\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9DnUYuWfVw5N"
      },
      "source": [
        "## 準備 Cifar 10 資料"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EzuSrrfzVw5Q",
        "outputId": "24cc17c4-8bed-4158-a1b3-b0cae3386004",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103
        }
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
        "x_train, x_valid, y_train, y_valid = train_test_split(x_train, y_train, \n",
        "                                                      stratify=y_train,\n",
        "                                                      random_state=2020, \n",
        "                                                      test_size=0.2)\n",
        "print(x_train.shape, y_train.shape) #(50000, 32, 32, 3)\n",
        "print(x_valid.shape, y_test.shape)\n",
        "## Normalize Data\n",
        "def normalize(X_train, X_valid, X_test):\n",
        "    mean = np.mean(X_train,axis=(0,1,2,3))\n",
        "    std = np.std(X_train, axis=(0, 1, 2, 3))\n",
        "    X_train = (X_train-mean)/(std+1e-7)\n",
        "    X_valid = (X_valid-mean)/(std+1e-7)\n",
        "    X_test = (X_test-mean)/(std+1e-7)\n",
        "    return X_train, X_valid, X_test\n",
        "    \n",
        "    \n",
        "## Normalize Training and Testset    \n",
        "x_train, x_valid, x_test = normalize(x_train, x_valid, x_test) \n",
        "\n",
        "## OneHot Label 由(None, 1)-(None, 10)\n",
        "## ex. label=2,變成[0,0,1,0,0,0,0,0,0,0]\n",
        "#one_hot=OneHotEncoder()\n",
        "#y_train=one_hot.fit_transform(y_train).toarray()\n",
        "#y_test=one_hot.transform(y_test).toarray()\n",
        "\n",
        "aug = tf.keras.preprocessing.image.ImageDataGenerator(rotation_range=15,\n",
        "                                                      width_shift_range= 0.1,\n",
        "                                                      height_shift_range= 0.1,\n",
        "                                                      shear_range= 10,\n",
        "                                                      zoom_range=[0.9, 1.1],\n",
        "                                                      horizontal_flip=True,\n",
        "                                                      )\n",
        "\n",
        "train_ds = tf.data.Dataset.from_generator(lambda: aug.flow(x_train, y_train.astype(np.float32), shuffle=True), \n",
        "                                          output_shapes=([32, 32, 32, 3], [32, 1]),\n",
        "                                          output_types = (tf.float32, tf.float32),\n",
        "                                          )\n",
        "#train_ds = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
        "valid_ds = tf.data.Dataset.from_tensor_slices((x_valid, y_valid))\n",
        "\n",
        "steps_per_epoch = x_train.shape[0]//32\n",
        "validation_step = x_valid.shape[0]//32\n",
        "steps_per_epoch, validation_step"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 4s 0us/step\n",
            "(40000, 32, 32, 3) (40000, 1)\n",
            "(10000, 32, 32, 3) (10000, 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1250, 312)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jN0O_agjVw5W"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8evWxhcALFkf",
        "outputId": "8efce7e7-36d2-494f-e331-8747c9f7d698",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "train_ds.element_spec"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorSpec(shape=(32, 32, 32, 3), dtype=tf.float32, name=None),\n",
              " TensorSpec(shape=(32, 1), dtype=tf.float32, name=None))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kFd5a4cnFv7g",
        "outputId": "b1466a06-b2d8-4660-f3b9-0433339a1df1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "for i in train_ds:\n",
        "    print(i[0].shape, i[1].shape)\n",
        "    break"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(32, 32, 32, 3) (32, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S0jn91DypaZX"
      },
      "source": [
        "train_ds = train_ds.prefetch(1000)#.batch(32, drop_remainder=True).prefetch(1000)\n",
        "valid_ds = valid_ds.batch(32, drop_remainder=True).cache()"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ecNiZeNOVw5X",
        "outputId": "968c81a5-e15d-474d-93e0-e325abb4960c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# compile the model (should be done *after* setting layers to non-trainable)\n",
        "model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate=0.001/10),\n",
        "              loss = 'sparse_categorical_crossentropy', \n",
        "              metrics = ['accuracy'])\n",
        "history = model.fit(train_ds, \n",
        "                    #batch_size=32, \n",
        "                    steps_per_epoch = steps_per_epoch,\n",
        "                    epochs=40,\n",
        "                    validation_data = valid_ds,\n",
        "                    #validation_data = (x_valid, y_valid), \n",
        "                    #validation_steps = x_valid.shape[0]//32-1,\n",
        "                    )"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/40\n",
            "1250/1250 [==============================] - 18s 14ms/step - loss: 5.5301 - accuracy: 0.5117 - val_loss: 4.1712 - val_accuracy: 0.6551\n",
            "Epoch 2/40\n",
            "1250/1250 [==============================] - 22s 18ms/step - loss: 3.6110 - accuracy: 0.6192 - val_loss: 2.8708 - val_accuracy: 0.6912\n",
            "Epoch 3/40\n",
            "1250/1250 [==============================] - 22s 18ms/step - loss: 2.6417 - accuracy: 0.6416 - val_loss: 2.1676 - val_accuracy: 0.7060\n",
            "Epoch 4/40\n",
            "1250/1250 [==============================] - 22s 17ms/step - loss: 2.0927 - accuracy: 0.6591 - val_loss: 1.7510 - val_accuracy: 0.7171\n",
            "Epoch 5/40\n",
            "1250/1250 [==============================] - 22s 17ms/step - loss: 1.7607 - accuracy: 0.6648 - val_loss: 1.5119 - val_accuracy: 0.7152\n",
            "Epoch 6/40\n",
            "1250/1250 [==============================] - 22s 17ms/step - loss: 1.5392 - accuracy: 0.6737 - val_loss: 1.3201 - val_accuracy: 0.7259\n",
            "Epoch 7/40\n",
            "1250/1250 [==============================] - 22s 17ms/step - loss: 1.3938 - accuracy: 0.6786 - val_loss: 1.2190 - val_accuracy: 0.7226\n",
            "Epoch 8/40\n",
            "1250/1250 [==============================] - 22s 17ms/step - loss: 1.2979 - accuracy: 0.6804 - val_loss: 1.1389 - val_accuracy: 0.7258\n",
            "Epoch 9/40\n",
            "1250/1250 [==============================] - 22s 17ms/step - loss: 1.2229 - accuracy: 0.6825 - val_loss: 1.0657 - val_accuracy: 0.7293\n",
            "Epoch 10/40\n",
            "1250/1250 [==============================] - 22s 18ms/step - loss: 1.1759 - accuracy: 0.6842 - val_loss: 1.0333 - val_accuracy: 0.7293\n",
            "Epoch 11/40\n",
            "1250/1250 [==============================] - 22s 18ms/step - loss: 1.1290 - accuracy: 0.6905 - val_loss: 0.9967 - val_accuracy: 0.7307\n",
            "Epoch 12/40\n",
            "1250/1250 [==============================] - 22s 18ms/step - loss: 1.1060 - accuracy: 0.6910 - val_loss: 0.9554 - val_accuracy: 0.7424\n",
            "Epoch 13/40\n",
            "1250/1250 [==============================] - 22s 17ms/step - loss: 1.0840 - accuracy: 0.6922 - val_loss: 0.9411 - val_accuracy: 0.7433\n",
            "Epoch 14/40\n",
            "1250/1250 [==============================] - 22s 18ms/step - loss: 1.0650 - accuracy: 0.6938 - val_loss: 0.9411 - val_accuracy: 0.7325\n",
            "Epoch 15/40\n",
            "1250/1250 [==============================] - 22s 18ms/step - loss: 1.0506 - accuracy: 0.6953 - val_loss: 0.9365 - val_accuracy: 0.7340\n",
            "Epoch 16/40\n",
            "1250/1250 [==============================] - 22s 17ms/step - loss: 1.0419 - accuracy: 0.6956 - val_loss: 0.9281 - val_accuracy: 0.7318\n",
            "Epoch 17/40\n",
            "1250/1250 [==============================] - 22s 17ms/step - loss: 1.0326 - accuracy: 0.6970 - val_loss: 0.9078 - val_accuracy: 0.7373\n",
            "Epoch 18/40\n",
            "1250/1250 [==============================] - 21s 17ms/step - loss: 1.0304 - accuracy: 0.6943 - val_loss: 0.8990 - val_accuracy: 0.7401\n",
            "Epoch 19/40\n",
            "1250/1250 [==============================] - 21s 17ms/step - loss: 1.0197 - accuracy: 0.6987 - val_loss: 0.9182 - val_accuracy: 0.7321\n",
            "Epoch 20/40\n",
            "1250/1250 [==============================] - 21s 17ms/step - loss: 1.0170 - accuracy: 0.6977 - val_loss: 0.8905 - val_accuracy: 0.7419\n",
            "Epoch 21/40\n",
            "1250/1250 [==============================] - 21s 17ms/step - loss: 1.0043 - accuracy: 0.7016 - val_loss: 0.8976 - val_accuracy: 0.7366\n",
            "Epoch 22/40\n",
            "1250/1250 [==============================] - 21s 17ms/step - loss: 1.0090 - accuracy: 0.6983 - val_loss: 0.8833 - val_accuracy: 0.7447\n",
            "Epoch 23/40\n",
            "1250/1250 [==============================] - 21s 17ms/step - loss: 1.0033 - accuracy: 0.6982 - val_loss: 0.8861 - val_accuracy: 0.7460\n",
            "Epoch 24/40\n",
            "1250/1250 [==============================] - 21s 17ms/step - loss: 1.0067 - accuracy: 0.6991 - val_loss: 0.8649 - val_accuracy: 0.7523\n",
            "Epoch 25/40\n",
            "1250/1250 [==============================] - 21s 17ms/step - loss: 1.0087 - accuracy: 0.6982 - val_loss: 0.8684 - val_accuracy: 0.7481\n",
            "Epoch 26/40\n",
            "1250/1250 [==============================] - 21s 17ms/step - loss: 1.0005 - accuracy: 0.6991 - val_loss: 0.8777 - val_accuracy: 0.7464\n",
            "Epoch 27/40\n",
            "1250/1250 [==============================] - 21s 17ms/step - loss: 1.0023 - accuracy: 0.7011 - val_loss: 0.8795 - val_accuracy: 0.7410\n",
            "Epoch 28/40\n",
            "1250/1250 [==============================] - 21s 17ms/step - loss: 0.9960 - accuracy: 0.7032 - val_loss: 0.8717 - val_accuracy: 0.7467\n",
            "Epoch 29/40\n",
            "1250/1250 [==============================] - 21s 17ms/step - loss: 0.9936 - accuracy: 0.7024 - val_loss: 0.8815 - val_accuracy: 0.7412\n",
            "Epoch 30/40\n",
            "1250/1250 [==============================] - 21s 17ms/step - loss: 0.9921 - accuracy: 0.7033 - val_loss: 0.8831 - val_accuracy: 0.7439\n",
            "Epoch 31/40\n",
            "1250/1250 [==============================] - 21s 17ms/step - loss: 0.9917 - accuracy: 0.7021 - val_loss: 0.8618 - val_accuracy: 0.7475\n",
            "Epoch 32/40\n",
            "1250/1250 [==============================] - 21s 17ms/step - loss: 0.9926 - accuracy: 0.7052 - val_loss: 0.8817 - val_accuracy: 0.7417\n",
            "Epoch 33/40\n",
            "1250/1250 [==============================] - 21s 17ms/step - loss: 0.9907 - accuracy: 0.7031 - val_loss: 0.8757 - val_accuracy: 0.7397\n",
            "Epoch 34/40\n",
            "1250/1250 [==============================] - 21s 17ms/step - loss: 0.9953 - accuracy: 0.7006 - val_loss: 0.8687 - val_accuracy: 0.7432\n",
            "Epoch 35/40\n",
            "1250/1250 [==============================] - 21s 17ms/step - loss: 0.9880 - accuracy: 0.7045 - val_loss: 0.8723 - val_accuracy: 0.7466\n",
            "Epoch 36/40\n",
            "1250/1250 [==============================] - 21s 17ms/step - loss: 0.9874 - accuracy: 0.7071 - val_loss: 0.8601 - val_accuracy: 0.7496\n",
            "Epoch 37/40\n",
            "1250/1250 [==============================] - 21s 17ms/step - loss: 0.9866 - accuracy: 0.7044 - val_loss: 0.8703 - val_accuracy: 0.7450\n",
            "Epoch 38/40\n",
            "1250/1250 [==============================] - 21s 17ms/step - loss: 0.9876 - accuracy: 0.7033 - val_loss: 0.8722 - val_accuracy: 0.7483\n",
            "Epoch 39/40\n",
            "1250/1250 [==============================] - 21s 17ms/step - loss: 0.9846 - accuracy: 0.7054 - val_loss: 0.8689 - val_accuracy: 0.7455\n",
            "Epoch 40/40\n",
            "1250/1250 [==============================] - 21s 17ms/step - loss: 0.9827 - accuracy: 0.7075 - val_loss: 0.8600 - val_accuracy: 0.7525\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "00NqvZNh-8jd",
        "outputId": "624da976-8efd-4ceb-9f4c-d43f531ed553",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "history.history.keys()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IPvbMHN5-v8j",
        "outputId": "d7cebfce-f156-4b11-91ed-cbaa31b60fb6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.subplot(121)\n",
        "plt.plot(history.history['loss'][1:])\n",
        "plt.plot(history.history['val_loss'][1:])\n",
        "plt.subplot(122)\n",
        "plt.plot(history.history['accuracy'][1:])\n",
        "plt.plot(history.history['val_accuracy'][1:])"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f089a9eeb70>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lVW0RdRtZ9LP",
        "outputId": "0e2bd79f-9b1e-4036-f248-95c931d928b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "history2 = model.fit(train_ds, \n",
        "                    #batch_size=32, \n",
        "                    steps_per_epoch = steps_per_epoch,\n",
        "                    epochs=40,\n",
        "                    validation_data = valid_ds,\n",
        "                    #validation_data = (x_valid, y_valid), \n",
        "                    #validation_steps = x_valid.shape[0]//32-1,\n",
        "                    )"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/40\n",
            "1250/1250 [==============================] - 23s 18ms/step - loss: 0.9877 - accuracy: 0.7046 - val_loss: 0.8672 - val_accuracy: 0.7455\n",
            "Epoch 2/40\n",
            "1250/1250 [==============================] - 22s 17ms/step - loss: 0.9872 - accuracy: 0.7036 - val_loss: 0.8829 - val_accuracy: 0.7398\n",
            "Epoch 3/40\n",
            "1250/1250 [==============================] - 21s 17ms/step - loss: 0.9880 - accuracy: 0.7031 - val_loss: 0.8772 - val_accuracy: 0.7416\n",
            "Epoch 4/40\n",
            "1250/1250 [==============================] - 21s 17ms/step - loss: 0.9874 - accuracy: 0.7060 - val_loss: 0.8803 - val_accuracy: 0.7419\n",
            "Epoch 5/40\n",
            "1250/1250 [==============================] - 21s 17ms/step - loss: 0.9800 - accuracy: 0.7079 - val_loss: 0.8769 - val_accuracy: 0.7417\n",
            "Epoch 6/40\n",
            "1250/1250 [==============================] - 21s 17ms/step - loss: 0.9798 - accuracy: 0.7056 - val_loss: 0.8872 - val_accuracy: 0.7397\n",
            "Epoch 7/40\n",
            "1250/1250 [==============================] - 21s 17ms/step - loss: 0.9779 - accuracy: 0.7054 - val_loss: 0.8696 - val_accuracy: 0.7455\n",
            "Epoch 8/40\n",
            "1250/1250 [==============================] - 21s 16ms/step - loss: 0.9828 - accuracy: 0.7070 - val_loss: 0.8694 - val_accuracy: 0.7437\n",
            "Epoch 9/40\n",
            "1250/1250 [==============================] - 20s 16ms/step - loss: 0.9787 - accuracy: 0.7067 - val_loss: 0.8661 - val_accuracy: 0.7479\n",
            "Epoch 10/40\n",
            "1250/1250 [==============================] - 20s 16ms/step - loss: 0.9775 - accuracy: 0.7091 - val_loss: 0.8686 - val_accuracy: 0.7469\n",
            "Epoch 11/40\n",
            "1250/1250 [==============================] - 21s 16ms/step - loss: 0.9787 - accuracy: 0.7094 - val_loss: 0.8580 - val_accuracy: 0.7509\n",
            "Epoch 12/40\n",
            "1250/1250 [==============================] - 21s 16ms/step - loss: 0.9758 - accuracy: 0.7089 - val_loss: 0.8826 - val_accuracy: 0.7406\n",
            "Epoch 13/40\n",
            "1250/1250 [==============================] - 20s 16ms/step - loss: 0.9771 - accuracy: 0.7109 - val_loss: 0.8491 - val_accuracy: 0.7536\n",
            "Epoch 14/40\n",
            "1250/1250 [==============================] - 20s 16ms/step - loss: 0.9774 - accuracy: 0.7092 - val_loss: 0.8677 - val_accuracy: 0.7455\n",
            "Epoch 15/40\n",
            "1250/1250 [==============================] - 20s 16ms/step - loss: 0.9823 - accuracy: 0.7073 - val_loss: 0.8700 - val_accuracy: 0.7471\n",
            "Epoch 16/40\n",
            "1250/1250 [==============================] - 21s 17ms/step - loss: 0.9741 - accuracy: 0.7104 - val_loss: 0.8625 - val_accuracy: 0.7489\n",
            "Epoch 17/40\n",
            "1250/1250 [==============================] - 20s 16ms/step - loss: 0.9799 - accuracy: 0.7091 - val_loss: 0.8496 - val_accuracy: 0.7560\n",
            "Epoch 18/40\n",
            "1250/1250 [==============================] - 20s 16ms/step - loss: 0.9732 - accuracy: 0.7105 - val_loss: 0.8819 - val_accuracy: 0.7414\n",
            "Epoch 19/40\n",
            "1250/1250 [==============================] - 21s 16ms/step - loss: 0.9748 - accuracy: 0.7094 - val_loss: 0.8581 - val_accuracy: 0.7499\n",
            "Epoch 20/40\n",
            "1250/1250 [==============================] - 21s 16ms/step - loss: 0.9763 - accuracy: 0.7077 - val_loss: 0.8733 - val_accuracy: 0.7430\n",
            "Epoch 21/40\n",
            "1250/1250 [==============================] - 21s 17ms/step - loss: 0.9767 - accuracy: 0.7070 - val_loss: 0.8535 - val_accuracy: 0.7515\n",
            "Epoch 22/40\n",
            "1250/1250 [==============================] - 21s 17ms/step - loss: 0.9738 - accuracy: 0.7125 - val_loss: 0.8616 - val_accuracy: 0.7472\n",
            "Epoch 23/40\n",
            "1250/1250 [==============================] - 21s 17ms/step - loss: 0.9798 - accuracy: 0.7064 - val_loss: 0.8692 - val_accuracy: 0.7435\n",
            "Epoch 24/40\n",
            "1250/1250 [==============================] - 21s 16ms/step - loss: 0.9721 - accuracy: 0.7096 - val_loss: 0.8623 - val_accuracy: 0.7516\n",
            "Epoch 25/40\n",
            "1250/1250 [==============================] - 20s 16ms/step - loss: 0.9713 - accuracy: 0.7108 - val_loss: 0.8579 - val_accuracy: 0.7468\n",
            "Epoch 26/40\n",
            "1250/1250 [==============================] - 20s 16ms/step - loss: 0.9673 - accuracy: 0.7128 - val_loss: 0.8755 - val_accuracy: 0.7416\n",
            "Epoch 27/40\n",
            "1250/1250 [==============================] - 20s 16ms/step - loss: 0.9753 - accuracy: 0.7089 - val_loss: 0.8540 - val_accuracy: 0.7531\n",
            "Epoch 28/40\n",
            "1250/1250 [==============================] - 20s 16ms/step - loss: 0.9739 - accuracy: 0.7096 - val_loss: 0.8664 - val_accuracy: 0.7432\n",
            "Epoch 29/40\n",
            "1250/1250 [==============================] - 20s 16ms/step - loss: 0.9685 - accuracy: 0.7115 - val_loss: 0.8580 - val_accuracy: 0.7448\n",
            "Epoch 30/40\n",
            "1250/1250 [==============================] - 20s 16ms/step - loss: 0.9671 - accuracy: 0.7091 - val_loss: 0.8595 - val_accuracy: 0.7496\n",
            "Epoch 31/40\n",
            "1250/1250 [==============================] - 21s 16ms/step - loss: 0.9694 - accuracy: 0.7103 - val_loss: 0.8648 - val_accuracy: 0.7439\n",
            "Epoch 32/40\n",
            "1250/1250 [==============================] - 21s 16ms/step - loss: 0.9704 - accuracy: 0.7133 - val_loss: 0.8667 - val_accuracy: 0.7477\n",
            "Epoch 33/40\n",
            "1250/1250 [==============================] - 20s 16ms/step - loss: 0.9650 - accuracy: 0.7120 - val_loss: 0.8563 - val_accuracy: 0.7478\n",
            "Epoch 34/40\n",
            "1250/1250 [==============================] - 20s 16ms/step - loss: 0.9721 - accuracy: 0.7112 - val_loss: 0.8649 - val_accuracy: 0.7460\n",
            "Epoch 35/40\n",
            "1250/1250 [==============================] - 20s 16ms/step - loss: 0.9677 - accuracy: 0.7122 - val_loss: 0.8543 - val_accuracy: 0.7498\n",
            "Epoch 36/40\n",
            "1250/1250 [==============================] - 20s 16ms/step - loss: 0.9661 - accuracy: 0.7121 - val_loss: 0.8776 - val_accuracy: 0.7406\n",
            "Epoch 37/40\n",
            "1250/1250 [==============================] - 20s 16ms/step - loss: 0.9696 - accuracy: 0.7081 - val_loss: 0.8613 - val_accuracy: 0.7500\n",
            "Epoch 38/40\n",
            "1250/1250 [==============================] - 20s 16ms/step - loss: 0.9722 - accuracy: 0.7104 - val_loss: 0.8550 - val_accuracy: 0.7481\n",
            "Epoch 39/40\n",
            "1250/1250 [==============================] - 20s 16ms/step - loss: 0.9666 - accuracy: 0.7138 - val_loss: 0.8466 - val_accuracy: 0.7562\n",
            "Epoch 40/40\n",
            "1250/1250 [==============================] - 20s 16ms/step - loss: 0.9640 - accuracy: 0.7146 - val_loss: 0.8415 - val_accuracy: 0.7554\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Ovul0qjjYcv",
        "outputId": "a5752edc-b1bb-4353-c19b-27763f85df5a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.subplot(121)\n",
        "plt.plot(history2.history['loss'][1:])\n",
        "plt.plot(history2.history['val_loss'][1:])\n",
        "plt.subplot(122)\n",
        "plt.plot(history2.history['accuracy'][1:])\n",
        "plt.plot(history2.history['val_accuracy'][1:])"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f089a8ea908>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SoCO7L1tj_iU",
        "outputId": "3d86ac55-0e74-46b8-ab8b-25c20cf75148",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_flag = False\n",
        "for idx, layer in enumerate(model.layers):\n",
        "    if layer.name == 'block4_sepconv1_act': train_flag = True, print(idx+1)\n",
        "    if train_flag: layer.trainable = True\n",
        "    else: layer.trainable = False"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "27\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1zHVX1B1j5Vp",
        "outputId": "3dc9c139-2dda-46a7-905e-44f28b9d7724",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 703
        }
      },
      "source": [
        "# compile the model (should be done *after* setting layers to non-trainable)\n",
        "model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate=0.001/10/2),\n",
        "              loss = 'sparse_categorical_crossentropy', \n",
        "              metrics = ['accuracy'])\n",
        "history = model.fit(train_ds, \n",
        "                    #batch_size=32, \n",
        "                    steps_per_epoch = steps_per_epoch,\n",
        "                    epochs=20,\n",
        "                    validation_data = valid_ds,\n",
        "                    #validation_data = (x_valid, y_valid), \n",
        "                    #validation_steps = x_valid.shape[0]//32-1,\n",
        "                    )"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "1250/1250 [==============================] - 24s 20ms/step - loss: 0.9778 - accuracy: 0.7056 - val_loss: 0.8152 - val_accuracy: 0.7561\n",
            "Epoch 2/20\n",
            "1250/1250 [==============================] - 23s 19ms/step - loss: 0.8857 - accuracy: 0.7377 - val_loss: 0.7529 - val_accuracy: 0.7842\n",
            "Epoch 3/20\n",
            "1250/1250 [==============================] - 24s 19ms/step - loss: 0.8402 - accuracy: 0.7528 - val_loss: 0.7288 - val_accuracy: 0.7918\n",
            "Epoch 4/20\n",
            "1250/1250 [==============================] - 23s 19ms/step - loss: 0.8136 - accuracy: 0.7623 - val_loss: 0.7177 - val_accuracy: 0.7945\n",
            "Epoch 5/20\n",
            "1250/1250 [==============================] - 23s 19ms/step - loss: 0.7896 - accuracy: 0.7709 - val_loss: 0.7026 - val_accuracy: 0.7992\n",
            "Epoch 6/20\n",
            "1250/1250 [==============================] - 23s 18ms/step - loss: 0.7707 - accuracy: 0.7718 - val_loss: 0.6861 - val_accuracy: 0.8007\n",
            "Epoch 7/20\n",
            "1250/1250 [==============================] - 23s 18ms/step - loss: 0.7471 - accuracy: 0.7792 - val_loss: 0.6887 - val_accuracy: 0.8020\n",
            "Epoch 8/20\n",
            "1250/1250 [==============================] - 23s 19ms/step - loss: 0.7339 - accuracy: 0.7829 - val_loss: 0.6656 - val_accuracy: 0.8087\n",
            "Epoch 9/20\n",
            "1250/1250 [==============================] - 23s 19ms/step - loss: 0.7135 - accuracy: 0.7904 - val_loss: 0.6642 - val_accuracy: 0.8087\n",
            "Epoch 10/20\n",
            "1250/1250 [==============================] - 23s 19ms/step - loss: 0.7033 - accuracy: 0.7934 - val_loss: 0.6537 - val_accuracy: 0.8107\n",
            "Epoch 11/20\n",
            "1250/1250 [==============================] - 23s 19ms/step - loss: 0.6892 - accuracy: 0.8001 - val_loss: 0.6469 - val_accuracy: 0.8137\n",
            "Epoch 12/20\n",
            "1250/1250 [==============================] - 23s 19ms/step - loss: 0.6789 - accuracy: 0.8034 - val_loss: 0.6276 - val_accuracy: 0.8173\n",
            "Epoch 13/20\n",
            "1250/1250 [==============================] - 23s 19ms/step - loss: 0.6749 - accuracy: 0.8031 - val_loss: 0.6226 - val_accuracy: 0.8207\n",
            "Epoch 14/20\n",
            "1250/1250 [==============================] - 23s 18ms/step - loss: 0.6609 - accuracy: 0.8078 - val_loss: 0.6184 - val_accuracy: 0.8194\n",
            "Epoch 15/20\n",
            "1250/1250 [==============================] - 23s 19ms/step - loss: 0.6516 - accuracy: 0.8124 - val_loss: 0.6122 - val_accuracy: 0.8226\n",
            "Epoch 16/20\n",
            "1250/1250 [==============================] - 23s 18ms/step - loss: 0.6458 - accuracy: 0.8128 - val_loss: 0.6185 - val_accuracy: 0.8220\n",
            "Epoch 17/20\n",
            "1250/1250 [==============================] - 23s 18ms/step - loss: 0.6329 - accuracy: 0.8165 - val_loss: 0.6182 - val_accuracy: 0.8216\n",
            "Epoch 18/20\n",
            "1250/1250 [==============================] - 23s 18ms/step - loss: 0.6296 - accuracy: 0.8166 - val_loss: 0.6086 - val_accuracy: 0.8254\n",
            "Epoch 19/20\n",
            "1250/1250 [==============================] - 23s 19ms/step - loss: 0.6233 - accuracy: 0.8198 - val_loss: 0.5936 - val_accuracy: 0.8329\n",
            "Epoch 20/20\n",
            "1250/1250 [==============================] - 23s 18ms/step - loss: 0.6140 - accuracy: 0.8238 - val_loss: 0.6058 - val_accuracy: 0.8246\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Am-ZfIPemRFL"
      },
      "source": [
        "model.save('model_0824.h5')"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rxGgVwY6ojz9"
      },
      "source": [
        "model = tf.keras.models.load_model('model_0824.h5')"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0DP4YsOBpgAX"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uWQ1GcQmo2If",
        "outputId": "14012d17-cc8f-4dd6-9b1b-4686dd4ccffa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_flag = False\n",
        "for idx, layer in enumerate(model.layers):\n",
        "    if layer.name == 'block3_sepconv1_act': train_flag = True, print(idx+1)\n",
        "    if train_flag: layer.trainable = True\n",
        "    else: layer.trainable = False"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "17\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yrXPOUjjmMT9",
        "outputId": "1b2f402d-b926-465e-ac37-54bb36beb039",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# compile the model (should be done *after* setting layers to non-trainable)\n",
        "model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate=0.001/10/10),\n",
        "              loss = 'sparse_categorical_crossentropy', \n",
        "              metrics = ['accuracy'])\n",
        "history = model.fit(train_ds, \n",
        "                    #batch_size=32, \n",
        "                    steps_per_epoch = steps_per_epoch,\n",
        "                    epochs=40,\n",
        "                    validation_data = valid_ds,\n",
        "                    #validation_data = (x_valid, y_valid), \n",
        "                    #validation_steps = x_valid.shape[0]//32-1,\n",
        "                    )"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/40\n",
            "1250/1250 [==============================] - 26s 21ms/step - loss: 0.6336 - accuracy: 0.8163 - val_loss: 0.6009 - val_accuracy: 0.8269\n",
            "Epoch 2/40\n",
            "1250/1250 [==============================] - 24s 20ms/step - loss: 0.6058 - accuracy: 0.8242 - val_loss: 0.5877 - val_accuracy: 0.8321\n",
            "Epoch 3/40\n",
            "1250/1250 [==============================] - 24s 19ms/step - loss: 0.5923 - accuracy: 0.8315 - val_loss: 0.5782 - val_accuracy: 0.8333\n",
            "Epoch 4/40\n",
            "1250/1250 [==============================] - 24s 19ms/step - loss: 0.5889 - accuracy: 0.8300 - val_loss: 0.5757 - val_accuracy: 0.8379\n",
            "Epoch 5/40\n",
            "1250/1250 [==============================] - 24s 19ms/step - loss: 0.5819 - accuracy: 0.8330 - val_loss: 0.5686 - val_accuracy: 0.8388\n",
            "Epoch 6/40\n",
            "1250/1250 [==============================] - 23s 19ms/step - loss: 0.5706 - accuracy: 0.8377 - val_loss: 0.5626 - val_accuracy: 0.8406\n",
            "Epoch 7/40\n",
            "1250/1250 [==============================] - 23s 19ms/step - loss: 0.5652 - accuracy: 0.8386 - val_loss: 0.5635 - val_accuracy: 0.8389\n",
            "Epoch 8/40\n",
            "1250/1250 [==============================] - 24s 19ms/step - loss: 0.5620 - accuracy: 0.8399 - val_loss: 0.5592 - val_accuracy: 0.8421\n",
            "Epoch 9/40\n",
            "1250/1250 [==============================] - 23s 19ms/step - loss: 0.5550 - accuracy: 0.8414 - val_loss: 0.5576 - val_accuracy: 0.8427\n",
            "Epoch 10/40\n",
            "1250/1250 [==============================] - 23s 19ms/step - loss: 0.5502 - accuracy: 0.8444 - val_loss: 0.5549 - val_accuracy: 0.8414\n",
            "Epoch 11/40\n",
            "1250/1250 [==============================] - 24s 19ms/step - loss: 0.5434 - accuracy: 0.8440 - val_loss: 0.5496 - val_accuracy: 0.8441\n",
            "Epoch 12/40\n",
            "1250/1250 [==============================] - 24s 19ms/step - loss: 0.5421 - accuracy: 0.8454 - val_loss: 0.5414 - val_accuracy: 0.8450\n",
            "Epoch 13/40\n",
            "1250/1250 [==============================] - 24s 19ms/step - loss: 0.5366 - accuracy: 0.8469 - val_loss: 0.5412 - val_accuracy: 0.8444\n",
            "Epoch 14/40\n",
            "1250/1250 [==============================] - 24s 19ms/step - loss: 0.5336 - accuracy: 0.8475 - val_loss: 0.5431 - val_accuracy: 0.8444\n",
            "Epoch 15/40\n",
            "1250/1250 [==============================] - 24s 19ms/step - loss: 0.5324 - accuracy: 0.8492 - val_loss: 0.5430 - val_accuracy: 0.8436\n",
            "Epoch 16/40\n",
            "1250/1250 [==============================] - 23s 19ms/step - loss: 0.5318 - accuracy: 0.8493 - val_loss: 0.5437 - val_accuracy: 0.8443\n",
            "Epoch 17/40\n",
            "1250/1250 [==============================] - 24s 19ms/step - loss: 0.5216 - accuracy: 0.8511 - val_loss: 0.5352 - val_accuracy: 0.8455\n",
            "Epoch 18/40\n",
            "1250/1250 [==============================] - 23s 19ms/step - loss: 0.5173 - accuracy: 0.8536 - val_loss: 0.5353 - val_accuracy: 0.8456\n",
            "Epoch 19/40\n",
            "1250/1250 [==============================] - 23s 19ms/step - loss: 0.5115 - accuracy: 0.8572 - val_loss: 0.5333 - val_accuracy: 0.8480\n",
            "Epoch 20/40\n",
            "1250/1250 [==============================] - 23s 19ms/step - loss: 0.5171 - accuracy: 0.8533 - val_loss: 0.5247 - val_accuracy: 0.8494\n",
            "Epoch 21/40\n",
            "1250/1250 [==============================] - 24s 19ms/step - loss: 0.5085 - accuracy: 0.8562 - val_loss: 0.5274 - val_accuracy: 0.8487\n",
            "Epoch 22/40\n",
            "1250/1250 [==============================] - 24s 19ms/step - loss: 0.5088 - accuracy: 0.8556 - val_loss: 0.5275 - val_accuracy: 0.8455\n",
            "Epoch 23/40\n",
            "1250/1250 [==============================] - 24s 19ms/step - loss: 0.4986 - accuracy: 0.8604 - val_loss: 0.5310 - val_accuracy: 0.8457\n",
            "Epoch 24/40\n",
            "1250/1250 [==============================] - 23s 19ms/step - loss: 0.5055 - accuracy: 0.8588 - val_loss: 0.5219 - val_accuracy: 0.8504\n",
            "Epoch 25/40\n",
            "1250/1250 [==============================] - 23s 19ms/step - loss: 0.4977 - accuracy: 0.8601 - val_loss: 0.5300 - val_accuracy: 0.8478\n",
            "Epoch 26/40\n",
            "1250/1250 [==============================] - 23s 18ms/step - loss: 0.4977 - accuracy: 0.8600 - val_loss: 0.5218 - val_accuracy: 0.8510\n",
            "Epoch 27/40\n",
            "1250/1250 [==============================] - 23s 19ms/step - loss: 0.4989 - accuracy: 0.8602 - val_loss: 0.5241 - val_accuracy: 0.8499\n",
            "Epoch 28/40\n",
            "1250/1250 [==============================] - 24s 19ms/step - loss: 0.4920 - accuracy: 0.8623 - val_loss: 0.5232 - val_accuracy: 0.8502\n",
            "Epoch 29/40\n",
            "1250/1250 [==============================] - 23s 19ms/step - loss: 0.4889 - accuracy: 0.8618 - val_loss: 0.5229 - val_accuracy: 0.8499\n",
            "Epoch 30/40\n",
            "1250/1250 [==============================] - 23s 18ms/step - loss: 0.4906 - accuracy: 0.8605 - val_loss: 0.5190 - val_accuracy: 0.8514\n",
            "Epoch 31/40\n",
            "1250/1250 [==============================] - 23s 19ms/step - loss: 0.4849 - accuracy: 0.8621 - val_loss: 0.5154 - val_accuracy: 0.8513\n",
            "Epoch 32/40\n",
            "1250/1250 [==============================] - 23s 19ms/step - loss: 0.4827 - accuracy: 0.8638 - val_loss: 0.5156 - val_accuracy: 0.8522\n",
            "Epoch 33/40\n",
            "1250/1250 [==============================] - 23s 19ms/step - loss: 0.4841 - accuracy: 0.8629 - val_loss: 0.5116 - val_accuracy: 0.8527\n",
            "Epoch 34/40\n",
            "1250/1250 [==============================] - 23s 19ms/step - loss: 0.4781 - accuracy: 0.8669 - val_loss: 0.5160 - val_accuracy: 0.8530\n",
            "Epoch 35/40\n",
            "1250/1250 [==============================] - 24s 19ms/step - loss: 0.4717 - accuracy: 0.8685 - val_loss: 0.5141 - val_accuracy: 0.8527\n",
            "Epoch 36/40\n",
            "1250/1250 [==============================] - 23s 19ms/step - loss: 0.4747 - accuracy: 0.8667 - val_loss: 0.5095 - val_accuracy: 0.8518\n",
            "Epoch 37/40\n",
            "1250/1250 [==============================] - 23s 19ms/step - loss: 0.4707 - accuracy: 0.8686 - val_loss: 0.5120 - val_accuracy: 0.8518\n",
            "Epoch 38/40\n",
            "1250/1250 [==============================] - 23s 19ms/step - loss: 0.4672 - accuracy: 0.8702 - val_loss: 0.5101 - val_accuracy: 0.8543\n",
            "Epoch 39/40\n",
            "1250/1250 [==============================] - 23s 19ms/step - loss: 0.4661 - accuracy: 0.8691 - val_loss: 0.5093 - val_accuracy: 0.8540\n",
            "Epoch 40/40\n",
            "1250/1250 [==============================] - 23s 19ms/step - loss: 0.4662 - accuracy: 0.8698 - val_loss: 0.5078 - val_accuracy: 0.8547\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zL7BDrX5vI25"
      },
      "source": [
        "model.save('model_0854.h5')"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OVKDoSjhvJav",
        "outputId": "671f1404-44af-4a9d-ee26-bffa11a92eb3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "history = model.fit(train_ds, \n",
        "                    #batch_size=32, \n",
        "                    steps_per_epoch = steps_per_epoch,\n",
        "                    epochs=40,\n",
        "                    validation_data = valid_ds,\n",
        "                    #validation_data = (x_valid, y_valid), \n",
        "                    #validation_steps = x_valid.shape[0]//32-1,\n",
        "                    )"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/40\n",
            "1250/1250 [==============================] - 26s 21ms/step - loss: 0.4640 - accuracy: 0.8672 - val_loss: 0.5065 - val_accuracy: 0.8535\n",
            "Epoch 2/40\n",
            "1250/1250 [==============================] - 25s 20ms/step - loss: 0.4644 - accuracy: 0.8708 - val_loss: 0.5035 - val_accuracy: 0.8547\n",
            "Epoch 3/40\n",
            "1250/1250 [==============================] - 25s 20ms/step - loss: 0.4570 - accuracy: 0.8727 - val_loss: 0.5029 - val_accuracy: 0.8551\n",
            "Epoch 4/40\n",
            "1250/1250 [==============================] - 25s 20ms/step - loss: 0.4575 - accuracy: 0.8712 - val_loss: 0.5058 - val_accuracy: 0.8516\n",
            "Epoch 5/40\n",
            "1250/1250 [==============================] - 24s 19ms/step - loss: 0.4598 - accuracy: 0.8701 - val_loss: 0.5023 - val_accuracy: 0.8550\n",
            "Epoch 6/40\n",
            "1250/1250 [==============================] - 24s 20ms/step - loss: 0.4546 - accuracy: 0.8726 - val_loss: 0.5003 - val_accuracy: 0.8554\n",
            "Epoch 7/40\n",
            "1250/1250 [==============================] - 24s 19ms/step - loss: 0.4537 - accuracy: 0.8731 - val_loss: 0.5001 - val_accuracy: 0.8553\n",
            "Epoch 8/40\n",
            "1250/1250 [==============================] - 24s 19ms/step - loss: 0.4497 - accuracy: 0.8748 - val_loss: 0.4990 - val_accuracy: 0.8539\n",
            "Epoch 9/40\n",
            "1250/1250 [==============================] - 24s 19ms/step - loss: 0.4536 - accuracy: 0.8737 - val_loss: 0.5008 - val_accuracy: 0.8540\n",
            "Epoch 10/40\n",
            "1250/1250 [==============================] - 24s 19ms/step - loss: 0.4474 - accuracy: 0.8744 - val_loss: 0.4987 - val_accuracy: 0.8552\n",
            "Epoch 11/40\n",
            "1250/1250 [==============================] - 24s 19ms/step - loss: 0.4412 - accuracy: 0.8779 - val_loss: 0.4966 - val_accuracy: 0.8566\n",
            "Epoch 12/40\n",
            "1250/1250 [==============================] - 24s 19ms/step - loss: 0.4451 - accuracy: 0.8752 - val_loss: 0.4981 - val_accuracy: 0.8581\n",
            "Epoch 13/40\n",
            "1250/1250 [==============================] - 24s 19ms/step - loss: 0.4426 - accuracy: 0.8764 - val_loss: 0.4972 - val_accuracy: 0.8550\n",
            "Epoch 14/40\n",
            "1250/1250 [==============================] - 24s 19ms/step - loss: 0.4409 - accuracy: 0.8777 - val_loss: 0.4951 - val_accuracy: 0.8550\n",
            "Epoch 15/40\n",
            "1250/1250 [==============================] - 24s 19ms/step - loss: 0.4420 - accuracy: 0.8757 - val_loss: 0.4966 - val_accuracy: 0.8534\n",
            "Epoch 16/40\n",
            "1250/1250 [==============================] - 24s 19ms/step - loss: 0.4321 - accuracy: 0.8795 - val_loss: 0.4996 - val_accuracy: 0.8553\n",
            "Epoch 17/40\n",
            "1250/1250 [==============================] - 24s 19ms/step - loss: 0.4322 - accuracy: 0.8809 - val_loss: 0.4913 - val_accuracy: 0.8579\n",
            "Epoch 18/40\n",
            "1250/1250 [==============================] - 24s 19ms/step - loss: 0.4348 - accuracy: 0.8785 - val_loss: 0.4909 - val_accuracy: 0.8578\n",
            "Epoch 19/40\n",
            "1250/1250 [==============================] - 24s 19ms/step - loss: 0.4335 - accuracy: 0.8805 - val_loss: 0.4902 - val_accuracy: 0.8586\n",
            "Epoch 20/40\n",
            "1250/1250 [==============================] - 24s 19ms/step - loss: 0.4315 - accuracy: 0.8806 - val_loss: 0.4906 - val_accuracy: 0.8582\n",
            "Epoch 21/40\n",
            "1250/1250 [==============================] - 24s 19ms/step - loss: 0.4289 - accuracy: 0.8825 - val_loss: 0.4942 - val_accuracy: 0.8576\n",
            "Epoch 22/40\n",
            "1250/1250 [==============================] - 24s 19ms/step - loss: 0.4298 - accuracy: 0.8806 - val_loss: 0.4946 - val_accuracy: 0.8561\n",
            "Epoch 23/40\n",
            "1250/1250 [==============================] - 24s 19ms/step - loss: 0.4205 - accuracy: 0.8852 - val_loss: 0.4905 - val_accuracy: 0.8572\n",
            "Epoch 24/40\n",
            "1250/1250 [==============================] - 24s 19ms/step - loss: 0.4193 - accuracy: 0.8855 - val_loss: 0.4895 - val_accuracy: 0.8585\n",
            "Epoch 25/40\n",
            "1250/1250 [==============================] - 24s 19ms/step - loss: 0.4266 - accuracy: 0.8814 - val_loss: 0.4896 - val_accuracy: 0.8576\n",
            "Epoch 26/40\n",
            "1250/1250 [==============================] - 24s 19ms/step - loss: 0.4253 - accuracy: 0.8830 - val_loss: 0.4883 - val_accuracy: 0.8601\n",
            "Epoch 27/40\n",
            "1250/1250 [==============================] - 24s 19ms/step - loss: 0.4170 - accuracy: 0.8850 - val_loss: 0.4923 - val_accuracy: 0.8570\n",
            "Epoch 28/40\n",
            "1250/1250 [==============================] - 24s 19ms/step - loss: 0.4151 - accuracy: 0.8844 - val_loss: 0.4863 - val_accuracy: 0.8595\n",
            "Epoch 29/40\n",
            "1250/1250 [==============================] - 24s 19ms/step - loss: 0.4149 - accuracy: 0.8861 - val_loss: 0.4877 - val_accuracy: 0.8576\n",
            "Epoch 30/40\n",
            "1250/1250 [==============================] - 24s 19ms/step - loss: 0.4178 - accuracy: 0.8848 - val_loss: 0.4847 - val_accuracy: 0.8595\n",
            "Epoch 31/40\n",
            "1250/1250 [==============================] - 24s 19ms/step - loss: 0.4133 - accuracy: 0.8875 - val_loss: 0.4870 - val_accuracy: 0.8585\n",
            "Epoch 32/40\n",
            "1250/1250 [==============================] - 24s 19ms/step - loss: 0.4159 - accuracy: 0.8830 - val_loss: 0.4932 - val_accuracy: 0.8588\n",
            "Epoch 33/40\n",
            "1250/1250 [==============================] - 24s 19ms/step - loss: 0.4097 - accuracy: 0.8876 - val_loss: 0.4831 - val_accuracy: 0.8583\n",
            "Epoch 34/40\n",
            "1250/1250 [==============================] - 24s 19ms/step - loss: 0.4065 - accuracy: 0.8875 - val_loss: 0.4908 - val_accuracy: 0.8578\n",
            "Epoch 35/40\n",
            "1250/1250 [==============================] - 24s 19ms/step - loss: 0.4064 - accuracy: 0.8879 - val_loss: 0.4857 - val_accuracy: 0.8589\n",
            "Epoch 36/40\n",
            "1250/1250 [==============================] - 24s 19ms/step - loss: 0.4086 - accuracy: 0.8878 - val_loss: 0.4865 - val_accuracy: 0.8593\n",
            "Epoch 37/40\n",
            "1250/1250 [==============================] - 24s 19ms/step - loss: 0.4029 - accuracy: 0.8897 - val_loss: 0.4887 - val_accuracy: 0.8572\n",
            "Epoch 38/40\n",
            "1250/1250 [==============================] - 24s 19ms/step - loss: 0.4042 - accuracy: 0.8900 - val_loss: 0.4842 - val_accuracy: 0.8603\n",
            "Epoch 39/40\n",
            "1250/1250 [==============================] - 24s 19ms/step - loss: 0.4018 - accuracy: 0.8904 - val_loss: 0.4818 - val_accuracy: 0.8600\n",
            "Epoch 40/40\n",
            "1250/1250 [==============================] - 24s 19ms/step - loss: 0.4008 - accuracy: 0.8901 - val_loss: 0.4871 - val_accuracy: 0.8594\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nhy85NwbzIJH"
      },
      "source": [
        "model.save('model_0859.h5')"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zw6nAfxYzSae",
        "outputId": "72f28187-8521-4c4c-f41f-fafc79a92f04",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "history = model.fit(train_ds, \n",
        "                    #batch_size=32, \n",
        "                    steps_per_epoch = steps_per_epoch,\n",
        "                    epochs=40,\n",
        "                    validation_data = valid_ds,\n",
        "                    #validation_data = (x_valid, y_valid), \n",
        "                    #validation_steps = x_valid.shape[0]//32-1,\n",
        "                    )"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/40\n",
            "1250/1250 [==============================] - 25s 20ms/step - loss: 0.4017 - accuracy: 0.8890 - val_loss: 0.4834 - val_accuracy: 0.8615\n",
            "Epoch 2/40\n",
            "1250/1250 [==============================] - 24s 20ms/step - loss: 0.4035 - accuracy: 0.8885 - val_loss: 0.4837 - val_accuracy: 0.8598\n",
            "Epoch 3/40\n",
            "1250/1250 [==============================] - 24s 19ms/step - loss: 0.3973 - accuracy: 0.8910 - val_loss: 0.4866 - val_accuracy: 0.8592\n",
            "Epoch 4/40\n",
            "1250/1250 [==============================] - 24s 19ms/step - loss: 0.3958 - accuracy: 0.8917 - val_loss: 0.4864 - val_accuracy: 0.8583\n",
            "Epoch 5/40\n",
            "1250/1250 [==============================] - 24s 19ms/step - loss: 0.3984 - accuracy: 0.8904 - val_loss: 0.4830 - val_accuracy: 0.8612\n",
            "Epoch 6/40\n",
            "1250/1250 [==============================] - 24s 19ms/step - loss: 0.3954 - accuracy: 0.8913 - val_loss: 0.4821 - val_accuracy: 0.8606\n",
            "Epoch 7/40\n",
            "1250/1250 [==============================] - 24s 19ms/step - loss: 0.3939 - accuracy: 0.8928 - val_loss: 0.4802 - val_accuracy: 0.8634\n",
            "Epoch 8/40\n",
            "1250/1250 [==============================] - 24s 19ms/step - loss: 0.3921 - accuracy: 0.8952 - val_loss: 0.4827 - val_accuracy: 0.8618\n",
            "Epoch 9/40\n",
            "1250/1250 [==============================] - 24s 20ms/step - loss: 0.3957 - accuracy: 0.8913 - val_loss: 0.4833 - val_accuracy: 0.8599\n",
            "Epoch 10/40\n",
            "1250/1250 [==============================] - 24s 19ms/step - loss: 0.3889 - accuracy: 0.8933 - val_loss: 0.4795 - val_accuracy: 0.8623\n",
            "Epoch 11/40\n",
            "1250/1250 [==============================] - 24s 19ms/step - loss: 0.3904 - accuracy: 0.8939 - val_loss: 0.4813 - val_accuracy: 0.8598\n",
            "Epoch 12/40\n",
            "1250/1250 [==============================] - 24s 19ms/step - loss: 0.3882 - accuracy: 0.8937 - val_loss: 0.4813 - val_accuracy: 0.8634\n",
            "Epoch 13/40\n",
            "1250/1250 [==============================] - 24s 19ms/step - loss: 0.3853 - accuracy: 0.8960 - val_loss: 0.4808 - val_accuracy: 0.8606\n",
            "Epoch 14/40\n",
            "1250/1250 [==============================] - 24s 19ms/step - loss: 0.3870 - accuracy: 0.8946 - val_loss: 0.4786 - val_accuracy: 0.8618\n",
            "Epoch 15/40\n",
            "1250/1250 [==============================] - 24s 19ms/step - loss: 0.3894 - accuracy: 0.8940 - val_loss: 0.4822 - val_accuracy: 0.8596\n",
            "Epoch 16/40\n",
            "1250/1250 [==============================] - 24s 19ms/step - loss: 0.3827 - accuracy: 0.8972 - val_loss: 0.4822 - val_accuracy: 0.8600\n",
            "Epoch 17/40\n",
            "1250/1250 [==============================] - 24s 19ms/step - loss: 0.3847 - accuracy: 0.8954 - val_loss: 0.4818 - val_accuracy: 0.8625\n",
            "Epoch 18/40\n",
            "1250/1250 [==============================] - 24s 19ms/step - loss: 0.3815 - accuracy: 0.8976 - val_loss: 0.4848 - val_accuracy: 0.8574\n",
            "Epoch 19/40\n",
            "1250/1250 [==============================] - 24s 19ms/step - loss: 0.3813 - accuracy: 0.8980 - val_loss: 0.4788 - val_accuracy: 0.8617\n",
            "Epoch 20/40\n",
            "1250/1250 [==============================] - 24s 19ms/step - loss: 0.3764 - accuracy: 0.8993 - val_loss: 0.4816 - val_accuracy: 0.8625\n",
            "Epoch 21/40\n",
            "1250/1250 [==============================] - 23s 19ms/step - loss: 0.3756 - accuracy: 0.8986 - val_loss: 0.4848 - val_accuracy: 0.8603\n",
            "Epoch 22/40\n",
            "1250/1250 [==============================] - 24s 19ms/step - loss: 0.3816 - accuracy: 0.8953 - val_loss: 0.4828 - val_accuracy: 0.8627\n",
            "Epoch 23/40\n",
            "1250/1250 [==============================] - 24s 19ms/step - loss: 0.3804 - accuracy: 0.8960 - val_loss: 0.4791 - val_accuracy: 0.8619\n",
            "Epoch 24/40\n",
            "1250/1250 [==============================] - 24s 19ms/step - loss: 0.3758 - accuracy: 0.8989 - val_loss: 0.4757 - val_accuracy: 0.8630\n",
            "Epoch 25/40\n",
            "1250/1250 [==============================] - 24s 19ms/step - loss: 0.3725 - accuracy: 0.9001 - val_loss: 0.4778 - val_accuracy: 0.8642\n",
            "Epoch 26/40\n",
            "1250/1250 [==============================] - 24s 19ms/step - loss: 0.3763 - accuracy: 0.8999 - val_loss: 0.4759 - val_accuracy: 0.8656\n",
            "Epoch 27/40\n",
            "1250/1250 [==============================] - 24s 19ms/step - loss: 0.3706 - accuracy: 0.8991 - val_loss: 0.4764 - val_accuracy: 0.8640\n",
            "Epoch 28/40\n",
            "1250/1250 [==============================] - 24s 19ms/step - loss: 0.3744 - accuracy: 0.8972 - val_loss: 0.4726 - val_accuracy: 0.8630\n",
            "Epoch 29/40\n",
            "1250/1250 [==============================] - 24s 19ms/step - loss: 0.3725 - accuracy: 0.8995 - val_loss: 0.4734 - val_accuracy: 0.8635\n",
            "Epoch 30/40\n",
            "1250/1250 [==============================] - 24s 19ms/step - loss: 0.3684 - accuracy: 0.9014 - val_loss: 0.4765 - val_accuracy: 0.8631\n",
            "Epoch 31/40\n",
            "1250/1250 [==============================] - 23s 19ms/step - loss: 0.3716 - accuracy: 0.9012 - val_loss: 0.4764 - val_accuracy: 0.8621\n",
            "Epoch 32/40\n",
            "1250/1250 [==============================] - 24s 19ms/step - loss: 0.3684 - accuracy: 0.9024 - val_loss: 0.4766 - val_accuracy: 0.8640\n",
            "Epoch 33/40\n",
            "1250/1250 [==============================] - 24s 19ms/step - loss: 0.3650 - accuracy: 0.9022 - val_loss: 0.4730 - val_accuracy: 0.8649\n",
            "Epoch 34/40\n",
            "1250/1250 [==============================] - 24s 19ms/step - loss: 0.3673 - accuracy: 0.9027 - val_loss: 0.4768 - val_accuracy: 0.8624\n",
            "Epoch 35/40\n",
            "1250/1250 [==============================] - 24s 19ms/step - loss: 0.3636 - accuracy: 0.9034 - val_loss: 0.4743 - val_accuracy: 0.8627\n",
            "Epoch 36/40\n",
            "1250/1250 [==============================] - 24s 19ms/step - loss: 0.3658 - accuracy: 0.9014 - val_loss: 0.4766 - val_accuracy: 0.8605\n",
            "Epoch 37/40\n",
            "1250/1250 [==============================] - 23s 19ms/step - loss: 0.3630 - accuracy: 0.9035 - val_loss: 0.4718 - val_accuracy: 0.8644\n",
            "Epoch 38/40\n",
            "1250/1250 [==============================] - 23s 18ms/step - loss: 0.3608 - accuracy: 0.9032 - val_loss: 0.4792 - val_accuracy: 0.8634\n",
            "Epoch 39/40\n",
            "1250/1250 [==============================] - 23s 19ms/step - loss: 0.3612 - accuracy: 0.9040 - val_loss: 0.4807 - val_accuracy: 0.8620\n",
            "Epoch 40/40\n",
            "1250/1250 [==============================] - 23s 19ms/step - loss: 0.3633 - accuracy: 0.9040 - val_loss: 0.4754 - val_accuracy: 0.8624\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9-paH1Jj4RRU"
      },
      "source": [
        "model.save('model_08624.h5')"
      ],
      "execution_count": 33,
      "outputs": []
    }
  ]
}